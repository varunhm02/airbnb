{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import xgboost\n",
    "from rulefit import RuleFit\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from price_prediction_helper import cross_val_scores\n",
    "from sklearn.model_selection import cross_validate,RandomizedSearchCV,GridSearchCV\n",
    "from sklearn.metrics import make_scorer,mean_squared_error,r2_score\n",
    "from IPython.display import display\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "import warnings\n",
    "import time\n",
    "warnings.simplefilter(action='ignore')\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10916, 36)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('price_prediction_data_montreal_80_pca.csv',low_memory=False)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(data.drop(columns=['price']))\n",
    "y = data.price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV took 28.78 seconds to find optimal parameters.\n",
      "Optimal Parameters found :  {'criterion': 'mse', 'max_depth': 5, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'presort': False, 'random_state': 0, 'splitter': 'best'}\n",
      "R2 for optimal model :  0.31072062644350956\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_R2</th>\n",
       "      <th>split1_test_R2</th>\n",
       "      <th>split2_test_R2</th>\n",
       "      <th>split3_test_R2</th>\n",
       "      <th>split4_test_R2</th>\n",
       "      <th>split5_test_R2</th>\n",
       "      <th>split6_test_R2</th>\n",
       "      <th>split7_test_R2</th>\n",
       "      <th>split8_test_R2</th>\n",
       "      <th>split9_test_R2</th>\n",
       "      <th>mean_test_R2</th>\n",
       "      <th>std_test_R2</th>\n",
       "      <th>rank_test_R2</th>\n",
       "      <th>split0_test_RMSE</th>\n",
       "      <th>split1_test_RMSE</th>\n",
       "      <th>split2_test_RMSE</th>\n",
       "      <th>split3_test_RMSE</th>\n",
       "      <th>split4_test_RMSE</th>\n",
       "      <th>split5_test_RMSE</th>\n",
       "      <th>split6_test_RMSE</th>\n",
       "      <th>split7_test_RMSE</th>\n",
       "      <th>split8_test_RMSE</th>\n",
       "      <th>split9_test_RMSE</th>\n",
       "      <th>mean_test_RMSE</th>\n",
       "      <th>std_test_RMSE</th>\n",
       "      <th>rank_test_RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.203458</td>\n",
       "      <td>0.065687</td>\n",
       "      <td>0.008988</td>\n",
       "      <td>0.007127</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
       "      <td>0.218090</td>\n",
       "      <td>0.320599</td>\n",
       "      <td>0.272464</td>\n",
       "      <td>0.284154</td>\n",
       "      <td>0.284072</td>\n",
       "      <td>0.270737</td>\n",
       "      <td>0.297019</td>\n",
       "      <td>0.279566</td>\n",
       "      <td>0.351404</td>\n",
       "      <td>0.192711</td>\n",
       "      <td>0.277082</td>\n",
       "      <td>0.043105</td>\n",
       "      <td>13</td>\n",
       "      <td>234.173401</td>\n",
       "      <td>228.457399</td>\n",
       "      <td>250.681077</td>\n",
       "      <td>247.834834</td>\n",
       "      <td>236.075597</td>\n",
       "      <td>255.387258</td>\n",
       "      <td>225.737205</td>\n",
       "      <td>246.267766</td>\n",
       "      <td>216.166085</td>\n",
       "      <td>243.841347</td>\n",
       "      <td>238.462197</td>\n",
       "      <td>11.818184</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.164971</td>\n",
       "      <td>0.039095</td>\n",
       "      <td>0.005349</td>\n",
       "      <td>0.006902</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
       "      <td>0.218090</td>\n",
       "      <td>0.320599</td>\n",
       "      <td>0.272464</td>\n",
       "      <td>0.284154</td>\n",
       "      <td>0.284072</td>\n",
       "      <td>0.270737</td>\n",
       "      <td>0.297019</td>\n",
       "      <td>0.279566</td>\n",
       "      <td>0.351404</td>\n",
       "      <td>0.192711</td>\n",
       "      <td>0.277082</td>\n",
       "      <td>0.043105</td>\n",
       "      <td>13</td>\n",
       "      <td>234.173401</td>\n",
       "      <td>228.457399</td>\n",
       "      <td>250.681077</td>\n",
       "      <td>247.834834</td>\n",
       "      <td>236.075597</td>\n",
       "      <td>255.387258</td>\n",
       "      <td>225.737205</td>\n",
       "      <td>246.267766</td>\n",
       "      <td>216.166085</td>\n",
       "      <td>243.841347</td>\n",
       "      <td>238.462197</td>\n",
       "      <td>11.818184</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.140124</td>\n",
       "      <td>0.020175</td>\n",
       "      <td>0.004273</td>\n",
       "      <td>0.002259</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 4}</td>\n",
       "      <td>0.218090</td>\n",
       "      <td>0.320599</td>\n",
       "      <td>0.272464</td>\n",
       "      <td>0.284154</td>\n",
       "      <td>0.284072</td>\n",
       "      <td>0.270737</td>\n",
       "      <td>0.297019</td>\n",
       "      <td>0.279566</td>\n",
       "      <td>0.351404</td>\n",
       "      <td>0.192711</td>\n",
       "      <td>0.277082</td>\n",
       "      <td>0.043105</td>\n",
       "      <td>13</td>\n",
       "      <td>234.173401</td>\n",
       "      <td>228.457399</td>\n",
       "      <td>250.681077</td>\n",
       "      <td>247.834834</td>\n",
       "      <td>236.075597</td>\n",
       "      <td>255.387258</td>\n",
       "      <td>225.737205</td>\n",
       "      <td>246.267766</td>\n",
       "      <td>216.166085</td>\n",
       "      <td>243.841347</td>\n",
       "      <td>238.462197</td>\n",
       "      <td>11.818184</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.135198</td>\n",
       "      <td>0.028893</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>0.004632</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 5}</td>\n",
       "      <td>0.218090</td>\n",
       "      <td>0.320599</td>\n",
       "      <td>0.272464</td>\n",
       "      <td>0.284154</td>\n",
       "      <td>0.284072</td>\n",
       "      <td>0.270737</td>\n",
       "      <td>0.297019</td>\n",
       "      <td>0.279566</td>\n",
       "      <td>0.351404</td>\n",
       "      <td>0.192711</td>\n",
       "      <td>0.277082</td>\n",
       "      <td>0.043105</td>\n",
       "      <td>13</td>\n",
       "      <td>234.173401</td>\n",
       "      <td>228.457399</td>\n",
       "      <td>250.681077</td>\n",
       "      <td>247.834834</td>\n",
       "      <td>236.075597</td>\n",
       "      <td>255.387258</td>\n",
       "      <td>225.737205</td>\n",
       "      <td>246.267766</td>\n",
       "      <td>216.166085</td>\n",
       "      <td>243.841347</td>\n",
       "      <td>238.462197</td>\n",
       "      <td>11.818184</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.488218</td>\n",
       "      <td>0.103453</td>\n",
       "      <td>0.001297</td>\n",
       "      <td>0.001345</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 2}</td>\n",
       "      <td>0.219935</td>\n",
       "      <td>0.361209</td>\n",
       "      <td>0.345863</td>\n",
       "      <td>0.308323</td>\n",
       "      <td>0.322523</td>\n",
       "      <td>0.302979</td>\n",
       "      <td>0.335093</td>\n",
       "      <td>0.339495</td>\n",
       "      <td>0.354004</td>\n",
       "      <td>0.217782</td>\n",
       "      <td>0.310721</td>\n",
       "      <td>0.049157</td>\n",
       "      <td>1</td>\n",
       "      <td>233.620765</td>\n",
       "      <td>214.801654</td>\n",
       "      <td>225.390700</td>\n",
       "      <td>239.467342</td>\n",
       "      <td>223.396431</td>\n",
       "      <td>244.096399</td>\n",
       "      <td>213.511089</td>\n",
       "      <td>225.781943</td>\n",
       "      <td>215.299802</td>\n",
       "      <td>236.268465</td>\n",
       "      <td>227.163459</td>\n",
       "      <td>10.304841</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.499648</td>\n",
       "      <td>0.132466</td>\n",
       "      <td>0.003890</td>\n",
       "      <td>0.003436</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 3}</td>\n",
       "      <td>0.219935</td>\n",
       "      <td>0.361209</td>\n",
       "      <td>0.345863</td>\n",
       "      <td>0.308323</td>\n",
       "      <td>0.322523</td>\n",
       "      <td>0.302979</td>\n",
       "      <td>0.335093</td>\n",
       "      <td>0.339495</td>\n",
       "      <td>0.354004</td>\n",
       "      <td>0.217782</td>\n",
       "      <td>0.310721</td>\n",
       "      <td>0.049157</td>\n",
       "      <td>1</td>\n",
       "      <td>233.620765</td>\n",
       "      <td>214.801654</td>\n",
       "      <td>225.390700</td>\n",
       "      <td>239.467342</td>\n",
       "      <td>223.396431</td>\n",
       "      <td>244.096399</td>\n",
       "      <td>213.511089</td>\n",
       "      <td>225.781943</td>\n",
       "      <td>215.299802</td>\n",
       "      <td>236.268465</td>\n",
       "      <td>227.163459</td>\n",
       "      <td>10.304841</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.398276</td>\n",
       "      <td>0.048885</td>\n",
       "      <td>0.004239</td>\n",
       "      <td>0.003875</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 4}</td>\n",
       "      <td>0.219935</td>\n",
       "      <td>0.361209</td>\n",
       "      <td>0.345863</td>\n",
       "      <td>0.308323</td>\n",
       "      <td>0.322523</td>\n",
       "      <td>0.302979</td>\n",
       "      <td>0.335093</td>\n",
       "      <td>0.339495</td>\n",
       "      <td>0.354004</td>\n",
       "      <td>0.217782</td>\n",
       "      <td>0.310721</td>\n",
       "      <td>0.049157</td>\n",
       "      <td>1</td>\n",
       "      <td>233.620765</td>\n",
       "      <td>214.801654</td>\n",
       "      <td>225.390700</td>\n",
       "      <td>239.467342</td>\n",
       "      <td>223.396431</td>\n",
       "      <td>244.096399</td>\n",
       "      <td>213.511089</td>\n",
       "      <td>225.781943</td>\n",
       "      <td>215.299802</td>\n",
       "      <td>236.268465</td>\n",
       "      <td>227.163459</td>\n",
       "      <td>10.304841</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.328016</td>\n",
       "      <td>0.040683</td>\n",
       "      <td>0.002274</td>\n",
       "      <td>0.003045</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 5}</td>\n",
       "      <td>0.219935</td>\n",
       "      <td>0.361209</td>\n",
       "      <td>0.345863</td>\n",
       "      <td>0.308323</td>\n",
       "      <td>0.322523</td>\n",
       "      <td>0.302979</td>\n",
       "      <td>0.335093</td>\n",
       "      <td>0.339495</td>\n",
       "      <td>0.354004</td>\n",
       "      <td>0.217782</td>\n",
       "      <td>0.310721</td>\n",
       "      <td>0.049157</td>\n",
       "      <td>1</td>\n",
       "      <td>233.620765</td>\n",
       "      <td>214.801654</td>\n",
       "      <td>225.390700</td>\n",
       "      <td>239.467342</td>\n",
       "      <td>223.396431</td>\n",
       "      <td>244.096399</td>\n",
       "      <td>213.511089</td>\n",
       "      <td>225.781943</td>\n",
       "      <td>215.299802</td>\n",
       "      <td>236.268465</td>\n",
       "      <td>227.163459</td>\n",
       "      <td>10.304841</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.394355</td>\n",
       "      <td>0.059264</td>\n",
       "      <td>0.002321</td>\n",
       "      <td>0.003057</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 6, 'min_samples_split': 2}</td>\n",
       "      <td>0.205864</td>\n",
       "      <td>0.349689</td>\n",
       "      <td>0.348291</td>\n",
       "      <td>0.312033</td>\n",
       "      <td>0.321694</td>\n",
       "      <td>0.307653</td>\n",
       "      <td>0.322869</td>\n",
       "      <td>0.329630</td>\n",
       "      <td>0.338042</td>\n",
       "      <td>0.156236</td>\n",
       "      <td>0.299200</td>\n",
       "      <td>0.061519</td>\n",
       "      <td>6</td>\n",
       "      <td>237.835099</td>\n",
       "      <td>218.675603</td>\n",
       "      <td>224.553987</td>\n",
       "      <td>238.182689</td>\n",
       "      <td>223.669981</td>\n",
       "      <td>242.459270</td>\n",
       "      <td>217.436317</td>\n",
       "      <td>229.154265</td>\n",
       "      <td>220.619523</td>\n",
       "      <td>254.858431</td>\n",
       "      <td>230.744516</td>\n",
       "      <td>11.578005</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.398244</td>\n",
       "      <td>0.063673</td>\n",
       "      <td>0.001421</td>\n",
       "      <td>0.003007</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 6, 'min_samples_split': 3}</td>\n",
       "      <td>0.205887</td>\n",
       "      <td>0.349689</td>\n",
       "      <td>0.348291</td>\n",
       "      <td>0.313501</td>\n",
       "      <td>0.321640</td>\n",
       "      <td>0.306620</td>\n",
       "      <td>0.322869</td>\n",
       "      <td>0.329630</td>\n",
       "      <td>0.338743</td>\n",
       "      <td>0.156236</td>\n",
       "      <td>0.299311</td>\n",
       "      <td>0.061578</td>\n",
       "      <td>5</td>\n",
       "      <td>237.828002</td>\n",
       "      <td>218.675603</td>\n",
       "      <td>224.553987</td>\n",
       "      <td>237.674569</td>\n",
       "      <td>223.687609</td>\n",
       "      <td>242.821220</td>\n",
       "      <td>217.436317</td>\n",
       "      <td>229.154265</td>\n",
       "      <td>220.385792</td>\n",
       "      <td>254.858431</td>\n",
       "      <td>230.707580</td>\n",
       "      <td>11.602745</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.384338</td>\n",
       "      <td>0.049825</td>\n",
       "      <td>0.001830</td>\n",
       "      <td>0.003689</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>{'max_depth': 6, 'min_samples_split': 4}</td>\n",
       "      <td>0.205887</td>\n",
       "      <td>0.349689</td>\n",
       "      <td>0.348291</td>\n",
       "      <td>0.313355</td>\n",
       "      <td>0.321640</td>\n",
       "      <td>0.306620</td>\n",
       "      <td>0.321466</td>\n",
       "      <td>0.329630</td>\n",
       "      <td>0.338743</td>\n",
       "      <td>0.156236</td>\n",
       "      <td>0.299156</td>\n",
       "      <td>0.061522</td>\n",
       "      <td>7</td>\n",
       "      <td>237.828002</td>\n",
       "      <td>218.675603</td>\n",
       "      <td>224.553987</td>\n",
       "      <td>237.724935</td>\n",
       "      <td>223.687609</td>\n",
       "      <td>242.821220</td>\n",
       "      <td>217.886879</td>\n",
       "      <td>229.154265</td>\n",
       "      <td>220.385792</td>\n",
       "      <td>254.858431</td>\n",
       "      <td>230.757672</td>\n",
       "      <td>11.554913</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.386652</td>\n",
       "      <td>0.054338</td>\n",
       "      <td>0.006241</td>\n",
       "      <td>0.006961</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 6, 'min_samples_split': 5}</td>\n",
       "      <td>0.205887</td>\n",
       "      <td>0.349689</td>\n",
       "      <td>0.348291</td>\n",
       "      <td>0.313355</td>\n",
       "      <td>0.321640</td>\n",
       "      <td>0.306620</td>\n",
       "      <td>0.321466</td>\n",
       "      <td>0.329630</td>\n",
       "      <td>0.338743</td>\n",
       "      <td>0.156236</td>\n",
       "      <td>0.299156</td>\n",
       "      <td>0.061522</td>\n",
       "      <td>7</td>\n",
       "      <td>237.828002</td>\n",
       "      <td>218.675603</td>\n",
       "      <td>224.553987</td>\n",
       "      <td>237.724935</td>\n",
       "      <td>223.687609</td>\n",
       "      <td>242.821220</td>\n",
       "      <td>217.886879</td>\n",
       "      <td>229.154265</td>\n",
       "      <td>220.385792</td>\n",
       "      <td>254.858431</td>\n",
       "      <td>230.757672</td>\n",
       "      <td>11.554913</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.432993</td>\n",
       "      <td>0.059563</td>\n",
       "      <td>0.002719</td>\n",
       "      <td>0.002867</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 7, 'min_samples_split': 2}</td>\n",
       "      <td>0.181442</td>\n",
       "      <td>0.331864</td>\n",
       "      <td>0.326819</td>\n",
       "      <td>0.311389</td>\n",
       "      <td>0.298637</td>\n",
       "      <td>0.301844</td>\n",
       "      <td>0.291888</td>\n",
       "      <td>0.328389</td>\n",
       "      <td>0.324549</td>\n",
       "      <td>0.147022</td>\n",
       "      <td>0.284384</td>\n",
       "      <td>0.061938</td>\n",
       "      <td>9</td>\n",
       "      <td>245.149019</td>\n",
       "      <td>224.669469</td>\n",
       "      <td>231.952530</td>\n",
       "      <td>238.405632</td>\n",
       "      <td>231.273017</td>\n",
       "      <td>244.493596</td>\n",
       "      <td>227.384934</td>\n",
       "      <td>229.578518</td>\n",
       "      <td>225.116559</td>\n",
       "      <td>257.641691</td>\n",
       "      <td>235.566496</td>\n",
       "      <td>10.144593</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.430663</td>\n",
       "      <td>0.053477</td>\n",
       "      <td>0.003843</td>\n",
       "      <td>0.003981</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 7, 'min_samples_split': 3}</td>\n",
       "      <td>0.182938</td>\n",
       "      <td>0.328555</td>\n",
       "      <td>0.319287</td>\n",
       "      <td>0.312325</td>\n",
       "      <td>0.298583</td>\n",
       "      <td>0.300763</td>\n",
       "      <td>0.291888</td>\n",
       "      <td>0.328389</td>\n",
       "      <td>0.325611</td>\n",
       "      <td>0.145042</td>\n",
       "      <td>0.283338</td>\n",
       "      <td>0.061489</td>\n",
       "      <td>11</td>\n",
       "      <td>244.701013</td>\n",
       "      <td>225.782106</td>\n",
       "      <td>234.547768</td>\n",
       "      <td>238.081665</td>\n",
       "      <td>231.290645</td>\n",
       "      <td>244.872132</td>\n",
       "      <td>227.384934</td>\n",
       "      <td>229.578518</td>\n",
       "      <td>224.762526</td>\n",
       "      <td>258.239664</td>\n",
       "      <td>235.924097</td>\n",
       "      <td>10.117948</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.424369</td>\n",
       "      <td>0.053621</td>\n",
       "      <td>0.002622</td>\n",
       "      <td>0.002977</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>{'max_depth': 7, 'min_samples_split': 4}</td>\n",
       "      <td>0.182938</td>\n",
       "      <td>0.332060</td>\n",
       "      <td>0.319287</td>\n",
       "      <td>0.313239</td>\n",
       "      <td>0.298583</td>\n",
       "      <td>0.300772</td>\n",
       "      <td>0.294687</td>\n",
       "      <td>0.325490</td>\n",
       "      <td>0.325611</td>\n",
       "      <td>0.143752</td>\n",
       "      <td>0.283642</td>\n",
       "      <td>0.061929</td>\n",
       "      <td>10</td>\n",
       "      <td>244.701013</td>\n",
       "      <td>224.603535</td>\n",
       "      <td>234.547768</td>\n",
       "      <td>237.765274</td>\n",
       "      <td>231.290645</td>\n",
       "      <td>244.869181</td>\n",
       "      <td>226.486242</td>\n",
       "      <td>230.569352</td>\n",
       "      <td>224.762526</td>\n",
       "      <td>258.629214</td>\n",
       "      <td>235.822475</td>\n",
       "      <td>10.342646</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.439434</td>\n",
       "      <td>0.060295</td>\n",
       "      <td>0.004491</td>\n",
       "      <td>0.006507</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 7, 'min_samples_split': 5}</td>\n",
       "      <td>0.182173</td>\n",
       "      <td>0.330565</td>\n",
       "      <td>0.324212</td>\n",
       "      <td>0.313239</td>\n",
       "      <td>0.299604</td>\n",
       "      <td>0.299568</td>\n",
       "      <td>0.298839</td>\n",
       "      <td>0.325490</td>\n",
       "      <td>0.325250</td>\n",
       "      <td>0.130926</td>\n",
       "      <td>0.282987</td>\n",
       "      <td>0.065237</td>\n",
       "      <td>12</td>\n",
       "      <td>244.930125</td>\n",
       "      <td>225.106282</td>\n",
       "      <td>232.850894</td>\n",
       "      <td>237.765274</td>\n",
       "      <td>230.954098</td>\n",
       "      <td>245.290872</td>\n",
       "      <td>225.152890</td>\n",
       "      <td>230.569352</td>\n",
       "      <td>224.882828</td>\n",
       "      <td>262.503286</td>\n",
       "      <td>236.000590</td>\n",
       "      <td>11.385966</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.461345</td>\n",
       "      <td>0.056397</td>\n",
       "      <td>0.002995</td>\n",
       "      <td>0.003786</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 8, 'min_samples_split': 2}</td>\n",
       "      <td>0.143583</td>\n",
       "      <td>0.310175</td>\n",
       "      <td>0.291219</td>\n",
       "      <td>0.296356</td>\n",
       "      <td>0.258739</td>\n",
       "      <td>0.293426</td>\n",
       "      <td>0.278329</td>\n",
       "      <td>0.297437</td>\n",
       "      <td>0.277906</td>\n",
       "      <td>0.077252</td>\n",
       "      <td>0.252442</td>\n",
       "      <td>0.073736</td>\n",
       "      <td>20</td>\n",
       "      <td>256.487399</td>\n",
       "      <td>231.962605</td>\n",
       "      <td>244.219013</td>\n",
       "      <td>243.610459</td>\n",
       "      <td>244.429343</td>\n",
       "      <td>247.441727</td>\n",
       "      <td>231.738868</td>\n",
       "      <td>240.158648</td>\n",
       "      <td>240.661876</td>\n",
       "      <td>278.715449</td>\n",
       "      <td>245.942539</td>\n",
       "      <td>12.871386</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.488988</td>\n",
       "      <td>0.064163</td>\n",
       "      <td>0.002836</td>\n",
       "      <td>0.003970</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 8, 'min_samples_split': 3}</td>\n",
       "      <td>0.143188</td>\n",
       "      <td>0.312225</td>\n",
       "      <td>0.290062</td>\n",
       "      <td>0.303438</td>\n",
       "      <td>0.266238</td>\n",
       "      <td>0.296357</td>\n",
       "      <td>0.280400</td>\n",
       "      <td>0.289925</td>\n",
       "      <td>0.277130</td>\n",
       "      <td>0.067625</td>\n",
       "      <td>0.252659</td>\n",
       "      <td>0.076549</td>\n",
       "      <td>19</td>\n",
       "      <td>256.605658</td>\n",
       "      <td>231.273330</td>\n",
       "      <td>244.617508</td>\n",
       "      <td>241.158459</td>\n",
       "      <td>241.956555</td>\n",
       "      <td>246.415255</td>\n",
       "      <td>231.073825</td>\n",
       "      <td>242.726510</td>\n",
       "      <td>240.920638</td>\n",
       "      <td>281.623423</td>\n",
       "      <td>245.837116</td>\n",
       "      <td>13.781501</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.469913</td>\n",
       "      <td>0.060505</td>\n",
       "      <td>0.003637</td>\n",
       "      <td>0.003689</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>{'max_depth': 8, 'min_samples_split': 4}</td>\n",
       "      <td>0.149494</td>\n",
       "      <td>0.317150</td>\n",
       "      <td>0.295270</td>\n",
       "      <td>0.309428</td>\n",
       "      <td>0.264881</td>\n",
       "      <td>0.289094</td>\n",
       "      <td>0.284399</td>\n",
       "      <td>0.293163</td>\n",
       "      <td>0.280806</td>\n",
       "      <td>0.075263</td>\n",
       "      <td>0.255895</td>\n",
       "      <td>0.074915</td>\n",
       "      <td>18</td>\n",
       "      <td>254.717218</td>\n",
       "      <td>229.617055</td>\n",
       "      <td>242.823103</td>\n",
       "      <td>239.084614</td>\n",
       "      <td>242.404026</td>\n",
       "      <td>248.958872</td>\n",
       "      <td>229.789586</td>\n",
       "      <td>241.619654</td>\n",
       "      <td>239.695376</td>\n",
       "      <td>279.316329</td>\n",
       "      <td>244.802583</td>\n",
       "      <td>13.569617</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.472569</td>\n",
       "      <td>0.050848</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>0.005162</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 8, 'min_samples_split': 5}</td>\n",
       "      <td>0.146198</td>\n",
       "      <td>0.309068</td>\n",
       "      <td>0.297286</td>\n",
       "      <td>0.304932</td>\n",
       "      <td>0.266115</td>\n",
       "      <td>0.301613</td>\n",
       "      <td>0.281255</td>\n",
       "      <td>0.295958</td>\n",
       "      <td>0.279649</td>\n",
       "      <td>0.084684</td>\n",
       "      <td>0.256676</td>\n",
       "      <td>0.073002</td>\n",
       "      <td>17</td>\n",
       "      <td>255.704279</td>\n",
       "      <td>232.334826</td>\n",
       "      <td>242.128357</td>\n",
       "      <td>240.641195</td>\n",
       "      <td>241.997026</td>\n",
       "      <td>244.574583</td>\n",
       "      <td>230.799325</td>\n",
       "      <td>240.664313</td>\n",
       "      <td>240.080872</td>\n",
       "      <td>276.470614</td>\n",
       "      <td>244.539539</td>\n",
       "      <td>12.427257</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.505699</td>\n",
       "      <td>0.064340</td>\n",
       "      <td>0.002598</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 9, 'min_samples_split': 2}</td>\n",
       "      <td>0.083743</td>\n",
       "      <td>0.283135</td>\n",
       "      <td>0.223298</td>\n",
       "      <td>0.280281</td>\n",
       "      <td>0.238506</td>\n",
       "      <td>0.280739</td>\n",
       "      <td>0.241845</td>\n",
       "      <td>0.251028</td>\n",
       "      <td>0.206658</td>\n",
       "      <td>0.032375</td>\n",
       "      <td>0.212161</td>\n",
       "      <td>0.081508</td>\n",
       "      <td>24</td>\n",
       "      <td>274.408889</td>\n",
       "      <td>241.054972</td>\n",
       "      <td>267.621910</td>\n",
       "      <td>249.175607</td>\n",
       "      <td>251.100934</td>\n",
       "      <td>251.884681</td>\n",
       "      <td>243.454414</td>\n",
       "      <td>256.022813</td>\n",
       "      <td>264.407481</td>\n",
       "      <td>292.270711</td>\n",
       "      <td>259.140241</td>\n",
       "      <td>14.932683</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.516916</td>\n",
       "      <td>0.070587</td>\n",
       "      <td>0.002693</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 9, 'min_samples_split': 3}</td>\n",
       "      <td>0.097169</td>\n",
       "      <td>0.277989</td>\n",
       "      <td>0.228510</td>\n",
       "      <td>0.283468</td>\n",
       "      <td>0.245091</td>\n",
       "      <td>0.284332</td>\n",
       "      <td>0.235755</td>\n",
       "      <td>0.268675</td>\n",
       "      <td>0.205529</td>\n",
       "      <td>0.045599</td>\n",
       "      <td>0.217212</td>\n",
       "      <td>0.077771</td>\n",
       "      <td>21</td>\n",
       "      <td>270.387911</td>\n",
       "      <td>242.785373</td>\n",
       "      <td>265.826162</td>\n",
       "      <td>248.072184</td>\n",
       "      <td>248.929704</td>\n",
       "      <td>250.626331</td>\n",
       "      <td>245.410152</td>\n",
       "      <td>249.990585</td>\n",
       "      <td>264.784074</td>\n",
       "      <td>288.276217</td>\n",
       "      <td>257.508869</td>\n",
       "      <td>13.653984</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.679770</td>\n",
       "      <td>0.182424</td>\n",
       "      <td>0.007779</td>\n",
       "      <td>0.014723</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>{'max_depth': 9, 'min_samples_split': 4}</td>\n",
       "      <td>0.085698</td>\n",
       "      <td>0.274184</td>\n",
       "      <td>0.236803</td>\n",
       "      <td>0.284305</td>\n",
       "      <td>0.248541</td>\n",
       "      <td>0.283230</td>\n",
       "      <td>0.229722</td>\n",
       "      <td>0.263952</td>\n",
       "      <td>0.202411</td>\n",
       "      <td>0.053201</td>\n",
       "      <td>0.216205</td>\n",
       "      <td>0.077599</td>\n",
       "      <td>23</td>\n",
       "      <td>273.823304</td>\n",
       "      <td>244.065028</td>\n",
       "      <td>262.968558</td>\n",
       "      <td>247.782415</td>\n",
       "      <td>247.791967</td>\n",
       "      <td>251.012463</td>\n",
       "      <td>247.347312</td>\n",
       "      <td>251.604891</td>\n",
       "      <td>265.823123</td>\n",
       "      <td>285.980007</td>\n",
       "      <td>257.819907</td>\n",
       "      <td>13.133204</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.744111</td>\n",
       "      <td>0.139223</td>\n",
       "      <td>0.005489</td>\n",
       "      <td>0.002936</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 9, 'min_samples_split': 5}</td>\n",
       "      <td>0.083806</td>\n",
       "      <td>0.288964</td>\n",
       "      <td>0.230328</td>\n",
       "      <td>0.291103</td>\n",
       "      <td>0.248840</td>\n",
       "      <td>0.273195</td>\n",
       "      <td>0.240210</td>\n",
       "      <td>0.259238</td>\n",
       "      <td>0.206017</td>\n",
       "      <td>0.048508</td>\n",
       "      <td>0.217021</td>\n",
       "      <td>0.079745</td>\n",
       "      <td>22</td>\n",
       "      <td>274.389956</td>\n",
       "      <td>239.094973</td>\n",
       "      <td>265.199728</td>\n",
       "      <td>245.429019</td>\n",
       "      <td>247.693568</td>\n",
       "      <td>254.526600</td>\n",
       "      <td>243.979402</td>\n",
       "      <td>253.216313</td>\n",
       "      <td>264.621248</td>\n",
       "      <td>287.397566</td>\n",
       "      <td>257.554837</td>\n",
       "      <td>14.421236</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.743410</td>\n",
       "      <td>0.143187</td>\n",
       "      <td>0.003987</td>\n",
       "      <td>0.001542</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 2}</td>\n",
       "      <td>0.033195</td>\n",
       "      <td>0.210786</td>\n",
       "      <td>0.190804</td>\n",
       "      <td>0.259635</td>\n",
       "      <td>0.190354</td>\n",
       "      <td>0.230752</td>\n",
       "      <td>0.210193</td>\n",
       "      <td>0.204235</td>\n",
       "      <td>0.127208</td>\n",
       "      <td>-0.035995</td>\n",
       "      <td>0.162117</td>\n",
       "      <td>0.089097</td>\n",
       "      <td>27</td>\n",
       "      <td>289.547398</td>\n",
       "      <td>265.383260</td>\n",
       "      <td>278.818044</td>\n",
       "      <td>256.323610</td>\n",
       "      <td>266.978908</td>\n",
       "      <td>269.390016</td>\n",
       "      <td>253.618332</td>\n",
       "      <td>272.018215</td>\n",
       "      <td>290.886893</td>\n",
       "      <td>312.921878</td>\n",
       "      <td>275.588655</td>\n",
       "      <td>17.077374</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.705511</td>\n",
       "      <td>0.106680</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>0.002044</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 3}</td>\n",
       "      <td>0.035688</td>\n",
       "      <td>0.221636</td>\n",
       "      <td>0.188532</td>\n",
       "      <td>0.256652</td>\n",
       "      <td>0.195246</td>\n",
       "      <td>0.239200</td>\n",
       "      <td>0.206563</td>\n",
       "      <td>0.203181</td>\n",
       "      <td>0.124897</td>\n",
       "      <td>-0.025822</td>\n",
       "      <td>0.164577</td>\n",
       "      <td>0.087469</td>\n",
       "      <td>26</td>\n",
       "      <td>288.800852</td>\n",
       "      <td>261.735120</td>\n",
       "      <td>279.601019</td>\n",
       "      <td>257.356235</td>\n",
       "      <td>265.365927</td>\n",
       "      <td>266.431573</td>\n",
       "      <td>254.783926</td>\n",
       "      <td>272.378635</td>\n",
       "      <td>291.657279</td>\n",
       "      <td>309.848965</td>\n",
       "      <td>274.795953</td>\n",
       "      <td>16.649883</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.791683</td>\n",
       "      <td>0.126071</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>0.003516</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 4}</td>\n",
       "      <td>0.029195</td>\n",
       "      <td>0.228100</td>\n",
       "      <td>0.210007</td>\n",
       "      <td>0.262798</td>\n",
       "      <td>0.188298</td>\n",
       "      <td>0.240543</td>\n",
       "      <td>0.197023</td>\n",
       "      <td>0.196179</td>\n",
       "      <td>0.102007</td>\n",
       "      <td>-0.056073</td>\n",
       "      <td>0.159808</td>\n",
       "      <td>0.097382</td>\n",
       "      <td>28</td>\n",
       "      <td>290.745317</td>\n",
       "      <td>259.561388</td>\n",
       "      <td>272.201529</td>\n",
       "      <td>255.228442</td>\n",
       "      <td>267.656969</td>\n",
       "      <td>265.961278</td>\n",
       "      <td>257.847436</td>\n",
       "      <td>274.771902</td>\n",
       "      <td>299.285961</td>\n",
       "      <td>318.986173</td>\n",
       "      <td>276.224640</td>\n",
       "      <td>19.556295</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.687759</td>\n",
       "      <td>0.146336</td>\n",
       "      <td>0.002694</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 5}</td>\n",
       "      <td>0.033445</td>\n",
       "      <td>0.224181</td>\n",
       "      <td>0.198275</td>\n",
       "      <td>0.262362</td>\n",
       "      <td>0.196009</td>\n",
       "      <td>0.246711</td>\n",
       "      <td>0.188528</td>\n",
       "      <td>0.223107</td>\n",
       "      <td>0.123999</td>\n",
       "      <td>-0.032492</td>\n",
       "      <td>0.166412</td>\n",
       "      <td>0.091448</td>\n",
       "      <td>25</td>\n",
       "      <td>289.472696</td>\n",
       "      <td>260.879229</td>\n",
       "      <td>276.243941</td>\n",
       "      <td>255.379522</td>\n",
       "      <td>265.114240</td>\n",
       "      <td>263.801345</td>\n",
       "      <td>260.575141</td>\n",
       "      <td>265.567070</td>\n",
       "      <td>291.956642</td>\n",
       "      <td>311.863583</td>\n",
       "      <td>274.085341</td>\n",
       "      <td>17.186175</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.854334</td>\n",
       "      <td>0.142882</td>\n",
       "      <td>0.013461</td>\n",
       "      <td>0.024733</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 2}</td>\n",
       "      <td>-0.315042</td>\n",
       "      <td>0.008950</td>\n",
       "      <td>-0.063454</td>\n",
       "      <td>0.029981</td>\n",
       "      <td>-0.121787</td>\n",
       "      <td>-0.017571</td>\n",
       "      <td>-0.064293</td>\n",
       "      <td>0.031475</td>\n",
       "      <td>-0.164485</td>\n",
       "      <td>-0.455058</td>\n",
       "      <td>-0.113128</td>\n",
       "      <td>0.151880</td>\n",
       "      <td>32</td>\n",
       "      <td>393.840422</td>\n",
       "      <td>333.253466</td>\n",
       "      <td>366.425642</td>\n",
       "      <td>335.832548</td>\n",
       "      <td>369.906728</td>\n",
       "      <td>356.352658</td>\n",
       "      <td>341.759716</td>\n",
       "      <td>331.073304</td>\n",
       "      <td>388.103414</td>\n",
       "      <td>439.499505</td>\n",
       "      <td>365.604740</td>\n",
       "      <td>32.500240</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.718481</td>\n",
       "      <td>0.097867</td>\n",
       "      <td>0.002693</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 3}</td>\n",
       "      <td>-0.269310</td>\n",
       "      <td>-0.030476</td>\n",
       "      <td>-0.085365</td>\n",
       "      <td>0.035827</td>\n",
       "      <td>-0.117963</td>\n",
       "      <td>-0.017583</td>\n",
       "      <td>-0.081193</td>\n",
       "      <td>0.002525</td>\n",
       "      <td>-0.140887</td>\n",
       "      <td>-0.425340</td>\n",
       "      <td>-0.112976</td>\n",
       "      <td>0.132656</td>\n",
       "      <td>31</td>\n",
       "      <td>380.144340</td>\n",
       "      <td>346.511028</td>\n",
       "      <td>373.975409</td>\n",
       "      <td>333.808859</td>\n",
       "      <td>368.645931</td>\n",
       "      <td>356.356703</td>\n",
       "      <td>347.186449</td>\n",
       "      <td>340.969278</td>\n",
       "      <td>380.238570</td>\n",
       "      <td>430.523035</td>\n",
       "      <td>365.835960</td>\n",
       "      <td>26.694437</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.690452</td>\n",
       "      <td>0.094863</td>\n",
       "      <td>0.002593</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 4}</td>\n",
       "      <td>-0.250751</td>\n",
       "      <td>-0.019897</td>\n",
       "      <td>-0.030357</td>\n",
       "      <td>0.065148</td>\n",
       "      <td>-0.098683</td>\n",
       "      <td>0.008905</td>\n",
       "      <td>-0.080249</td>\n",
       "      <td>0.016965</td>\n",
       "      <td>-0.112650</td>\n",
       "      <td>-0.446867</td>\n",
       "      <td>-0.094844</td>\n",
       "      <td>0.144018</td>\n",
       "      <td>30</td>\n",
       "      <td>374.585985</td>\n",
       "      <td>342.953598</td>\n",
       "      <td>355.021886</td>\n",
       "      <td>323.657265</td>\n",
       "      <td>362.288364</td>\n",
       "      <td>347.080738</td>\n",
       "      <td>346.883487</td>\n",
       "      <td>336.033066</td>\n",
       "      <td>370.827743</td>\n",
       "      <td>437.025528</td>\n",
       "      <td>359.635766</td>\n",
       "      <td>29.692344</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.644172</td>\n",
       "      <td>0.085161</td>\n",
       "      <td>0.002497</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 5}</td>\n",
       "      <td>-0.236187</td>\n",
       "      <td>0.027645</td>\n",
       "      <td>-0.039815</td>\n",
       "      <td>0.058390</td>\n",
       "      <td>-0.093285</td>\n",
       "      <td>0.031044</td>\n",
       "      <td>-0.076286</td>\n",
       "      <td>0.043441</td>\n",
       "      <td>-0.115341</td>\n",
       "      <td>-0.410471</td>\n",
       "      <td>-0.081086</td>\n",
       "      <td>0.139626</td>\n",
       "      <td>29</td>\n",
       "      <td>370.224273</td>\n",
       "      <td>326.966796</td>\n",
       "      <td>358.280715</td>\n",
       "      <td>325.996969</td>\n",
       "      <td>360.508453</td>\n",
       "      <td>339.327763</td>\n",
       "      <td>345.610857</td>\n",
       "      <td>326.982807</td>\n",
       "      <td>371.724481</td>\n",
       "      <td>426.031904</td>\n",
       "      <td>355.165502</td>\n",
       "      <td>28.885333</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.203458      0.065687         0.008988        0.007127   \n",
       "1        0.164971      0.039095         0.005349        0.006902   \n",
       "2        0.140124      0.020175         0.004273        0.002259   \n",
       "3        0.135198      0.028893         0.001892        0.004632   \n",
       "4        0.488218      0.103453         0.001297        0.001345   \n",
       "5        0.499648      0.132466         0.003890        0.003436   \n",
       "6        0.398276      0.048885         0.004239        0.003875   \n",
       "7        0.328016      0.040683         0.002274        0.003045   \n",
       "8        0.394355      0.059264         0.002321        0.003057   \n",
       "9        0.398244      0.063673         0.001421        0.003007   \n",
       "10       0.384338      0.049825         0.001830        0.003689   \n",
       "11       0.386652      0.054338         0.006241        0.006961   \n",
       "12       0.432993      0.059563         0.002719        0.002867   \n",
       "13       0.430663      0.053477         0.003843        0.003981   \n",
       "14       0.424369      0.053621         0.002622        0.002977   \n",
       "15       0.439434      0.060295         0.004491        0.006507   \n",
       "16       0.461345      0.056397         0.002995        0.003786   \n",
       "17       0.488988      0.064163         0.002836        0.003970   \n",
       "18       0.469913      0.060505         0.003637        0.003689   \n",
       "19       0.472569      0.050848         0.005115        0.005162   \n",
       "20       0.505699      0.064340         0.002598        0.000489   \n",
       "21       0.516916      0.070587         0.002693        0.000456   \n",
       "22       0.679770      0.182424         0.007779        0.014723   \n",
       "23       0.744111      0.139223         0.005489        0.002936   \n",
       "24       0.743410      0.143187         0.003987        0.001542   \n",
       "25       0.705511      0.106680         0.003990        0.002044   \n",
       "26       0.791683      0.126071         0.003690        0.003516   \n",
       "27       0.687759      0.146336         0.002694        0.000458   \n",
       "28       0.854334      0.142882         0.013461        0.024733   \n",
       "29       0.718481      0.097867         0.002693        0.000898   \n",
       "30       0.690452      0.094863         0.002593        0.000488   \n",
       "31       0.644172      0.085161         0.002497        0.000498   \n",
       "\n",
       "   param_max_depth param_min_samples_split  \\\n",
       "0                1                       2   \n",
       "1                1                       3   \n",
       "2                1                       4   \n",
       "3                1                       5   \n",
       "4                5                       2   \n",
       "5                5                       3   \n",
       "6                5                       4   \n",
       "7                5                       5   \n",
       "8                6                       2   \n",
       "9                6                       3   \n",
       "10               6                       4   \n",
       "11               6                       5   \n",
       "12               7                       2   \n",
       "13               7                       3   \n",
       "14               7                       4   \n",
       "15               7                       5   \n",
       "16               8                       2   \n",
       "17               8                       3   \n",
       "18               8                       4   \n",
       "19               8                       5   \n",
       "20               9                       2   \n",
       "21               9                       3   \n",
       "22               9                       4   \n",
       "23               9                       5   \n",
       "24              10                       2   \n",
       "25              10                       3   \n",
       "26              10                       4   \n",
       "27              10                       5   \n",
       "28              15                       2   \n",
       "29              15                       3   \n",
       "30              15                       4   \n",
       "31              15                       5   \n",
       "\n",
       "                                       params  split0_test_R2  split1_test_R2  \\\n",
       "0    {'max_depth': 1, 'min_samples_split': 2}        0.218090        0.320599   \n",
       "1    {'max_depth': 1, 'min_samples_split': 3}        0.218090        0.320599   \n",
       "2    {'max_depth': 1, 'min_samples_split': 4}        0.218090        0.320599   \n",
       "3    {'max_depth': 1, 'min_samples_split': 5}        0.218090        0.320599   \n",
       "4    {'max_depth': 5, 'min_samples_split': 2}        0.219935        0.361209   \n",
       "5    {'max_depth': 5, 'min_samples_split': 3}        0.219935        0.361209   \n",
       "6    {'max_depth': 5, 'min_samples_split': 4}        0.219935        0.361209   \n",
       "7    {'max_depth': 5, 'min_samples_split': 5}        0.219935        0.361209   \n",
       "8    {'max_depth': 6, 'min_samples_split': 2}        0.205864        0.349689   \n",
       "9    {'max_depth': 6, 'min_samples_split': 3}        0.205887        0.349689   \n",
       "10   {'max_depth': 6, 'min_samples_split': 4}        0.205887        0.349689   \n",
       "11   {'max_depth': 6, 'min_samples_split': 5}        0.205887        0.349689   \n",
       "12   {'max_depth': 7, 'min_samples_split': 2}        0.181442        0.331864   \n",
       "13   {'max_depth': 7, 'min_samples_split': 3}        0.182938        0.328555   \n",
       "14   {'max_depth': 7, 'min_samples_split': 4}        0.182938        0.332060   \n",
       "15   {'max_depth': 7, 'min_samples_split': 5}        0.182173        0.330565   \n",
       "16   {'max_depth': 8, 'min_samples_split': 2}        0.143583        0.310175   \n",
       "17   {'max_depth': 8, 'min_samples_split': 3}        0.143188        0.312225   \n",
       "18   {'max_depth': 8, 'min_samples_split': 4}        0.149494        0.317150   \n",
       "19   {'max_depth': 8, 'min_samples_split': 5}        0.146198        0.309068   \n",
       "20   {'max_depth': 9, 'min_samples_split': 2}        0.083743        0.283135   \n",
       "21   {'max_depth': 9, 'min_samples_split': 3}        0.097169        0.277989   \n",
       "22   {'max_depth': 9, 'min_samples_split': 4}        0.085698        0.274184   \n",
       "23   {'max_depth': 9, 'min_samples_split': 5}        0.083806        0.288964   \n",
       "24  {'max_depth': 10, 'min_samples_split': 2}        0.033195        0.210786   \n",
       "25  {'max_depth': 10, 'min_samples_split': 3}        0.035688        0.221636   \n",
       "26  {'max_depth': 10, 'min_samples_split': 4}        0.029195        0.228100   \n",
       "27  {'max_depth': 10, 'min_samples_split': 5}        0.033445        0.224181   \n",
       "28  {'max_depth': 15, 'min_samples_split': 2}       -0.315042        0.008950   \n",
       "29  {'max_depth': 15, 'min_samples_split': 3}       -0.269310       -0.030476   \n",
       "30  {'max_depth': 15, 'min_samples_split': 4}       -0.250751       -0.019897   \n",
       "31  {'max_depth': 15, 'min_samples_split': 5}       -0.236187        0.027645   \n",
       "\n",
       "    split2_test_R2  split3_test_R2  split4_test_R2  split5_test_R2  \\\n",
       "0         0.272464        0.284154        0.284072        0.270737   \n",
       "1         0.272464        0.284154        0.284072        0.270737   \n",
       "2         0.272464        0.284154        0.284072        0.270737   \n",
       "3         0.272464        0.284154        0.284072        0.270737   \n",
       "4         0.345863        0.308323        0.322523        0.302979   \n",
       "5         0.345863        0.308323        0.322523        0.302979   \n",
       "6         0.345863        0.308323        0.322523        0.302979   \n",
       "7         0.345863        0.308323        0.322523        0.302979   \n",
       "8         0.348291        0.312033        0.321694        0.307653   \n",
       "9         0.348291        0.313501        0.321640        0.306620   \n",
       "10        0.348291        0.313355        0.321640        0.306620   \n",
       "11        0.348291        0.313355        0.321640        0.306620   \n",
       "12        0.326819        0.311389        0.298637        0.301844   \n",
       "13        0.319287        0.312325        0.298583        0.300763   \n",
       "14        0.319287        0.313239        0.298583        0.300772   \n",
       "15        0.324212        0.313239        0.299604        0.299568   \n",
       "16        0.291219        0.296356        0.258739        0.293426   \n",
       "17        0.290062        0.303438        0.266238        0.296357   \n",
       "18        0.295270        0.309428        0.264881        0.289094   \n",
       "19        0.297286        0.304932        0.266115        0.301613   \n",
       "20        0.223298        0.280281        0.238506        0.280739   \n",
       "21        0.228510        0.283468        0.245091        0.284332   \n",
       "22        0.236803        0.284305        0.248541        0.283230   \n",
       "23        0.230328        0.291103        0.248840        0.273195   \n",
       "24        0.190804        0.259635        0.190354        0.230752   \n",
       "25        0.188532        0.256652        0.195246        0.239200   \n",
       "26        0.210007        0.262798        0.188298        0.240543   \n",
       "27        0.198275        0.262362        0.196009        0.246711   \n",
       "28       -0.063454        0.029981       -0.121787       -0.017571   \n",
       "29       -0.085365        0.035827       -0.117963       -0.017583   \n",
       "30       -0.030357        0.065148       -0.098683        0.008905   \n",
       "31       -0.039815        0.058390       -0.093285        0.031044   \n",
       "\n",
       "    split6_test_R2  split7_test_R2  split8_test_R2  split9_test_R2  \\\n",
       "0         0.297019        0.279566        0.351404        0.192711   \n",
       "1         0.297019        0.279566        0.351404        0.192711   \n",
       "2         0.297019        0.279566        0.351404        0.192711   \n",
       "3         0.297019        0.279566        0.351404        0.192711   \n",
       "4         0.335093        0.339495        0.354004        0.217782   \n",
       "5         0.335093        0.339495        0.354004        0.217782   \n",
       "6         0.335093        0.339495        0.354004        0.217782   \n",
       "7         0.335093        0.339495        0.354004        0.217782   \n",
       "8         0.322869        0.329630        0.338042        0.156236   \n",
       "9         0.322869        0.329630        0.338743        0.156236   \n",
       "10        0.321466        0.329630        0.338743        0.156236   \n",
       "11        0.321466        0.329630        0.338743        0.156236   \n",
       "12        0.291888        0.328389        0.324549        0.147022   \n",
       "13        0.291888        0.328389        0.325611        0.145042   \n",
       "14        0.294687        0.325490        0.325611        0.143752   \n",
       "15        0.298839        0.325490        0.325250        0.130926   \n",
       "16        0.278329        0.297437        0.277906        0.077252   \n",
       "17        0.280400        0.289925        0.277130        0.067625   \n",
       "18        0.284399        0.293163        0.280806        0.075263   \n",
       "19        0.281255        0.295958        0.279649        0.084684   \n",
       "20        0.241845        0.251028        0.206658        0.032375   \n",
       "21        0.235755        0.268675        0.205529        0.045599   \n",
       "22        0.229722        0.263952        0.202411        0.053201   \n",
       "23        0.240210        0.259238        0.206017        0.048508   \n",
       "24        0.210193        0.204235        0.127208       -0.035995   \n",
       "25        0.206563        0.203181        0.124897       -0.025822   \n",
       "26        0.197023        0.196179        0.102007       -0.056073   \n",
       "27        0.188528        0.223107        0.123999       -0.032492   \n",
       "28       -0.064293        0.031475       -0.164485       -0.455058   \n",
       "29       -0.081193        0.002525       -0.140887       -0.425340   \n",
       "30       -0.080249        0.016965       -0.112650       -0.446867   \n",
       "31       -0.076286        0.043441       -0.115341       -0.410471   \n",
       "\n",
       "    mean_test_R2  std_test_R2  rank_test_R2  split0_test_RMSE  \\\n",
       "0       0.277082     0.043105            13        234.173401   \n",
       "1       0.277082     0.043105            13        234.173401   \n",
       "2       0.277082     0.043105            13        234.173401   \n",
       "3       0.277082     0.043105            13        234.173401   \n",
       "4       0.310721     0.049157             1        233.620765   \n",
       "5       0.310721     0.049157             1        233.620765   \n",
       "6       0.310721     0.049157             1        233.620765   \n",
       "7       0.310721     0.049157             1        233.620765   \n",
       "8       0.299200     0.061519             6        237.835099   \n",
       "9       0.299311     0.061578             5        237.828002   \n",
       "10      0.299156     0.061522             7        237.828002   \n",
       "11      0.299156     0.061522             7        237.828002   \n",
       "12      0.284384     0.061938             9        245.149019   \n",
       "13      0.283338     0.061489            11        244.701013   \n",
       "14      0.283642     0.061929            10        244.701013   \n",
       "15      0.282987     0.065237            12        244.930125   \n",
       "16      0.252442     0.073736            20        256.487399   \n",
       "17      0.252659     0.076549            19        256.605658   \n",
       "18      0.255895     0.074915            18        254.717218   \n",
       "19      0.256676     0.073002            17        255.704279   \n",
       "20      0.212161     0.081508            24        274.408889   \n",
       "21      0.217212     0.077771            21        270.387911   \n",
       "22      0.216205     0.077599            23        273.823304   \n",
       "23      0.217021     0.079745            22        274.389956   \n",
       "24      0.162117     0.089097            27        289.547398   \n",
       "25      0.164577     0.087469            26        288.800852   \n",
       "26      0.159808     0.097382            28        290.745317   \n",
       "27      0.166412     0.091448            25        289.472696   \n",
       "28     -0.113128     0.151880            32        393.840422   \n",
       "29     -0.112976     0.132656            31        380.144340   \n",
       "30     -0.094844     0.144018            30        374.585985   \n",
       "31     -0.081086     0.139626            29        370.224273   \n",
       "\n",
       "    split1_test_RMSE  split2_test_RMSE  split3_test_RMSE  split4_test_RMSE  \\\n",
       "0         228.457399        250.681077        247.834834        236.075597   \n",
       "1         228.457399        250.681077        247.834834        236.075597   \n",
       "2         228.457399        250.681077        247.834834        236.075597   \n",
       "3         228.457399        250.681077        247.834834        236.075597   \n",
       "4         214.801654        225.390700        239.467342        223.396431   \n",
       "5         214.801654        225.390700        239.467342        223.396431   \n",
       "6         214.801654        225.390700        239.467342        223.396431   \n",
       "7         214.801654        225.390700        239.467342        223.396431   \n",
       "8         218.675603        224.553987        238.182689        223.669981   \n",
       "9         218.675603        224.553987        237.674569        223.687609   \n",
       "10        218.675603        224.553987        237.724935        223.687609   \n",
       "11        218.675603        224.553987        237.724935        223.687609   \n",
       "12        224.669469        231.952530        238.405632        231.273017   \n",
       "13        225.782106        234.547768        238.081665        231.290645   \n",
       "14        224.603535        234.547768        237.765274        231.290645   \n",
       "15        225.106282        232.850894        237.765274        230.954098   \n",
       "16        231.962605        244.219013        243.610459        244.429343   \n",
       "17        231.273330        244.617508        241.158459        241.956555   \n",
       "18        229.617055        242.823103        239.084614        242.404026   \n",
       "19        232.334826        242.128357        240.641195        241.997026   \n",
       "20        241.054972        267.621910        249.175607        251.100934   \n",
       "21        242.785373        265.826162        248.072184        248.929704   \n",
       "22        244.065028        262.968558        247.782415        247.791967   \n",
       "23        239.094973        265.199728        245.429019        247.693568   \n",
       "24        265.383260        278.818044        256.323610        266.978908   \n",
       "25        261.735120        279.601019        257.356235        265.365927   \n",
       "26        259.561388        272.201529        255.228442        267.656969   \n",
       "27        260.879229        276.243941        255.379522        265.114240   \n",
       "28        333.253466        366.425642        335.832548        369.906728   \n",
       "29        346.511028        373.975409        333.808859        368.645931   \n",
       "30        342.953598        355.021886        323.657265        362.288364   \n",
       "31        326.966796        358.280715        325.996969        360.508453   \n",
       "\n",
       "    split5_test_RMSE  split6_test_RMSE  split7_test_RMSE  split8_test_RMSE  \\\n",
       "0         255.387258        225.737205        246.267766        216.166085   \n",
       "1         255.387258        225.737205        246.267766        216.166085   \n",
       "2         255.387258        225.737205        246.267766        216.166085   \n",
       "3         255.387258        225.737205        246.267766        216.166085   \n",
       "4         244.096399        213.511089        225.781943        215.299802   \n",
       "5         244.096399        213.511089        225.781943        215.299802   \n",
       "6         244.096399        213.511089        225.781943        215.299802   \n",
       "7         244.096399        213.511089        225.781943        215.299802   \n",
       "8         242.459270        217.436317        229.154265        220.619523   \n",
       "9         242.821220        217.436317        229.154265        220.385792   \n",
       "10        242.821220        217.886879        229.154265        220.385792   \n",
       "11        242.821220        217.886879        229.154265        220.385792   \n",
       "12        244.493596        227.384934        229.578518        225.116559   \n",
       "13        244.872132        227.384934        229.578518        224.762526   \n",
       "14        244.869181        226.486242        230.569352        224.762526   \n",
       "15        245.290872        225.152890        230.569352        224.882828   \n",
       "16        247.441727        231.738868        240.158648        240.661876   \n",
       "17        246.415255        231.073825        242.726510        240.920638   \n",
       "18        248.958872        229.789586        241.619654        239.695376   \n",
       "19        244.574583        230.799325        240.664313        240.080872   \n",
       "20        251.884681        243.454414        256.022813        264.407481   \n",
       "21        250.626331        245.410152        249.990585        264.784074   \n",
       "22        251.012463        247.347312        251.604891        265.823123   \n",
       "23        254.526600        243.979402        253.216313        264.621248   \n",
       "24        269.390016        253.618332        272.018215        290.886893   \n",
       "25        266.431573        254.783926        272.378635        291.657279   \n",
       "26        265.961278        257.847436        274.771902        299.285961   \n",
       "27        263.801345        260.575141        265.567070        291.956642   \n",
       "28        356.352658        341.759716        331.073304        388.103414   \n",
       "29        356.356703        347.186449        340.969278        380.238570   \n",
       "30        347.080738        346.883487        336.033066        370.827743   \n",
       "31        339.327763        345.610857        326.982807        371.724481   \n",
       "\n",
       "    split9_test_RMSE  mean_test_RMSE  std_test_RMSE  rank_test_RMSE  \n",
       "0         243.841347      238.462197      11.818184              17  \n",
       "1         243.841347      238.462197      11.818184              17  \n",
       "2         243.841347      238.462197      11.818184              17  \n",
       "3         243.841347      238.462197      11.818184              17  \n",
       "4         236.268465      227.163459      10.304841              29  \n",
       "5         236.268465      227.163459      10.304841              29  \n",
       "6         236.268465      227.163459      10.304841              29  \n",
       "7         236.268465      227.163459      10.304841              29  \n",
       "8         254.858431      230.744516      11.578005              27  \n",
       "9         254.858431      230.707580      11.602745              28  \n",
       "10        254.858431      230.757672      11.554913              25  \n",
       "11        254.858431      230.757672      11.554913              25  \n",
       "12        257.641691      235.566496      10.144593              24  \n",
       "13        258.239664      235.924097      10.117948              22  \n",
       "14        258.629214      235.822475      10.342646              23  \n",
       "15        262.503286      236.000590      11.385966              21  \n",
       "16        278.715449      245.942539      12.871386              13  \n",
       "17        281.623423      245.837116      13.781501              14  \n",
       "18        279.316329      244.802583      13.569617              15  \n",
       "19        276.470614      244.539539      12.427257              16  \n",
       "20        292.270711      259.140241      14.932683               9  \n",
       "21        288.276217      257.508869      13.653984              12  \n",
       "22        285.980007      257.819907      13.133204              10  \n",
       "23        287.397566      257.554837      14.421236              11  \n",
       "24        312.921878      275.588655      17.077374               6  \n",
       "25        309.848965      274.795953      16.649883               7  \n",
       "26        318.986173      276.224640      19.556295               5  \n",
       "27        311.863583      274.085341      17.186175               8  \n",
       "28        439.499505      365.604740      32.500240               2  \n",
       "29        430.523035      365.835960      26.694437               1  \n",
       "30        437.025528      359.635766      29.692344               3  \n",
       "31        426.031904      355.165502      28.885333               4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params={ 'max_depth':[1,5,6,7,8,9,10,15],\n",
    "               \"min_samples_split\" : [2,3,4,5]}\n",
    "clf=DecisionTreeRegressor(random_state=0)\n",
    "\n",
    "scoring = {'R2': make_scorer(r2_score), 'RMSE': make_scorer(mean_squared_error)}\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid = params, scoring=scoring, refit='R2',cv=10, iid=False,n_jobs = -1)\n",
    "\n",
    "start = time.time()\n",
    "best_model = grid_search.fit(X, y)\n",
    "print(\"GridSearchCV took %.2f seconds to find optimal parameters.\" % (time.time() - start))\n",
    "print('Optimal Parameters found : ', best_model.best_estimator_.get_params())\n",
    "print('R2 for optimal model : ',best_model.best_score_)\n",
    "results = grid_search.cv_results_\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT RMSE : 14.98 (+/- 0.50)\n",
      "DT R2 Score: 0.33 (+/- 0.04)\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeRegressor(min_samples_split=4,max_depth=5,random_state=0)\n",
    "_,r2_scores,_,_=cross_val_scores('DT',clf,X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 352.29 seconds to find optimal parameters.\n",
      "Optimal Parameters found :  {'C': 10, 'cache_size': 200, 'coef0': 0.0, 'degree': 2, 'epsilon': 0.1, 'gamma': 'auto_deprecated', 'kernel': 'rbf', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "R2 for optimal model :  0.3660396585712893\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_degree</th>\n",
       "      <th>param_C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_R2</th>\n",
       "      <th>split1_test_R2</th>\n",
       "      <th>split2_test_R2</th>\n",
       "      <th>split3_test_R2</th>\n",
       "      <th>split4_test_R2</th>\n",
       "      <th>split5_test_R2</th>\n",
       "      <th>split6_test_R2</th>\n",
       "      <th>split7_test_R2</th>\n",
       "      <th>split8_test_R2</th>\n",
       "      <th>split9_test_R2</th>\n",
       "      <th>mean_test_R2</th>\n",
       "      <th>std_test_R2</th>\n",
       "      <th>rank_test_R2</th>\n",
       "      <th>split0_test_RMSE</th>\n",
       "      <th>split1_test_RMSE</th>\n",
       "      <th>split2_test_RMSE</th>\n",
       "      <th>split3_test_RMSE</th>\n",
       "      <th>split4_test_RMSE</th>\n",
       "      <th>split5_test_RMSE</th>\n",
       "      <th>split6_test_RMSE</th>\n",
       "      <th>split7_test_RMSE</th>\n",
       "      <th>split8_test_RMSE</th>\n",
       "      <th>split9_test_RMSE</th>\n",
       "      <th>mean_test_RMSE</th>\n",
       "      <th>std_test_RMSE</th>\n",
       "      <th>rank_test_RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44.847235</td>\n",
       "      <td>3.132622</td>\n",
       "      <td>7.355832</td>\n",
       "      <td>0.936051</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>{'degree': 2, 'C': 2}</td>\n",
       "      <td>0.269229</td>\n",
       "      <td>0.396686</td>\n",
       "      <td>0.377182</td>\n",
       "      <td>0.372466</td>\n",
       "      <td>0.362124</td>\n",
       "      <td>0.350930</td>\n",
       "      <td>0.337372</td>\n",
       "      <td>0.349408</td>\n",
       "      <td>0.432733</td>\n",
       "      <td>0.291858</td>\n",
       "      <td>0.353999</td>\n",
       "      <td>0.045078</td>\n",
       "      <td>5</td>\n",
       "      <td>218.857763</td>\n",
       "      <td>202.872119</td>\n",
       "      <td>214.599349</td>\n",
       "      <td>217.26014</td>\n",
       "      <td>210.338380</td>\n",
       "      <td>227.303935</td>\n",
       "      <td>212.779196</td>\n",
       "      <td>222.393490</td>\n",
       "      <td>189.060568</td>\n",
       "      <td>213.893764</td>\n",
       "      <td>212.935870</td>\n",
       "      <td>10.155892</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46.974804</td>\n",
       "      <td>5.103497</td>\n",
       "      <td>8.145459</td>\n",
       "      <td>1.790923</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>{'degree': 3, 'C': 5}</td>\n",
       "      <td>0.267603</td>\n",
       "      <td>0.414967</td>\n",
       "      <td>0.396830</td>\n",
       "      <td>0.387837</td>\n",
       "      <td>0.368225</td>\n",
       "      <td>0.358234</td>\n",
       "      <td>0.345171</td>\n",
       "      <td>0.362893</td>\n",
       "      <td>0.455539</td>\n",
       "      <td>0.289193</td>\n",
       "      <td>0.364649</td>\n",
       "      <td>0.052834</td>\n",
       "      <td>3</td>\n",
       "      <td>219.344810</td>\n",
       "      <td>196.725063</td>\n",
       "      <td>207.829268</td>\n",
       "      <td>211.93851</td>\n",
       "      <td>208.326349</td>\n",
       "      <td>224.745932</td>\n",
       "      <td>210.275106</td>\n",
       "      <td>217.783851</td>\n",
       "      <td>181.459855</td>\n",
       "      <td>214.698753</td>\n",
       "      <td>209.312750</td>\n",
       "      <td>11.767846</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47.488909</td>\n",
       "      <td>3.821192</td>\n",
       "      <td>7.563342</td>\n",
       "      <td>0.767480</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>{'degree': 2, 'C': 5}</td>\n",
       "      <td>0.267603</td>\n",
       "      <td>0.414967</td>\n",
       "      <td>0.396830</td>\n",
       "      <td>0.387837</td>\n",
       "      <td>0.368225</td>\n",
       "      <td>0.358234</td>\n",
       "      <td>0.345171</td>\n",
       "      <td>0.362893</td>\n",
       "      <td>0.455539</td>\n",
       "      <td>0.289193</td>\n",
       "      <td>0.364649</td>\n",
       "      <td>0.052834</td>\n",
       "      <td>3</td>\n",
       "      <td>219.344810</td>\n",
       "      <td>196.725063</td>\n",
       "      <td>207.829268</td>\n",
       "      <td>211.93851</td>\n",
       "      <td>208.326349</td>\n",
       "      <td>224.745932</td>\n",
       "      <td>210.275106</td>\n",
       "      <td>217.783851</td>\n",
       "      <td>181.459855</td>\n",
       "      <td>214.698753</td>\n",
       "      <td>209.312750</td>\n",
       "      <td>11.767846</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.247343</td>\n",
       "      <td>3.173769</td>\n",
       "      <td>8.720933</td>\n",
       "      <td>1.730915</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>{'degree': 2, 'C': 10}</td>\n",
       "      <td>0.259048</td>\n",
       "      <td>0.417299</td>\n",
       "      <td>0.408428</td>\n",
       "      <td>0.395174</td>\n",
       "      <td>0.364544</td>\n",
       "      <td>0.360125</td>\n",
       "      <td>0.347729</td>\n",
       "      <td>0.364213</td>\n",
       "      <td>0.462478</td>\n",
       "      <td>0.281361</td>\n",
       "      <td>0.366040</td>\n",
       "      <td>0.057937</td>\n",
       "      <td>1</td>\n",
       "      <td>221.906999</td>\n",
       "      <td>195.940848</td>\n",
       "      <td>203.833257</td>\n",
       "      <td>209.39840</td>\n",
       "      <td>209.540373</td>\n",
       "      <td>224.083892</td>\n",
       "      <td>209.453560</td>\n",
       "      <td>217.332516</td>\n",
       "      <td>179.147244</td>\n",
       "      <td>217.064631</td>\n",
       "      <td>208.770172</td>\n",
       "      <td>12.716664</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.640054</td>\n",
       "      <td>7.751921</td>\n",
       "      <td>4.288525</td>\n",
       "      <td>1.959367</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'degree': 3, 'C': 10}</td>\n",
       "      <td>0.259048</td>\n",
       "      <td>0.417299</td>\n",
       "      <td>0.408428</td>\n",
       "      <td>0.395174</td>\n",
       "      <td>0.364544</td>\n",
       "      <td>0.360125</td>\n",
       "      <td>0.347729</td>\n",
       "      <td>0.364213</td>\n",
       "      <td>0.462478</td>\n",
       "      <td>0.281361</td>\n",
       "      <td>0.366040</td>\n",
       "      <td>0.057937</td>\n",
       "      <td>1</td>\n",
       "      <td>221.906999</td>\n",
       "      <td>195.940848</td>\n",
       "      <td>203.833257</td>\n",
       "      <td>209.39840</td>\n",
       "      <td>209.540373</td>\n",
       "      <td>224.083892</td>\n",
       "      <td>209.453560</td>\n",
       "      <td>217.332516</td>\n",
       "      <td>179.147244</td>\n",
       "      <td>217.064631</td>\n",
       "      <td>208.770172</td>\n",
       "      <td>12.716664</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_degree  \\\n",
       "0      44.847235      3.132622         7.355832        0.936051            2   \n",
       "1      46.974804      5.103497         8.145459        1.790923            3   \n",
       "2      47.488909      3.821192         7.563342        0.767480            2   \n",
       "3      50.247343      3.173769         8.720933        1.730915            2   \n",
       "4      36.640054      7.751921         4.288525        1.959367            3   \n",
       "\n",
       "  param_C                  params  split0_test_R2  split1_test_R2  \\\n",
       "0       2   {'degree': 2, 'C': 2}        0.269229        0.396686   \n",
       "1       5   {'degree': 3, 'C': 5}        0.267603        0.414967   \n",
       "2       5   {'degree': 2, 'C': 5}        0.267603        0.414967   \n",
       "3      10  {'degree': 2, 'C': 10}        0.259048        0.417299   \n",
       "4      10  {'degree': 3, 'C': 10}        0.259048        0.417299   \n",
       "\n",
       "   split2_test_R2  split3_test_R2  split4_test_R2  split5_test_R2  \\\n",
       "0        0.377182        0.372466        0.362124        0.350930   \n",
       "1        0.396830        0.387837        0.368225        0.358234   \n",
       "2        0.396830        0.387837        0.368225        0.358234   \n",
       "3        0.408428        0.395174        0.364544        0.360125   \n",
       "4        0.408428        0.395174        0.364544        0.360125   \n",
       "\n",
       "   split6_test_R2  split7_test_R2  split8_test_R2  split9_test_R2  \\\n",
       "0        0.337372        0.349408        0.432733        0.291858   \n",
       "1        0.345171        0.362893        0.455539        0.289193   \n",
       "2        0.345171        0.362893        0.455539        0.289193   \n",
       "3        0.347729        0.364213        0.462478        0.281361   \n",
       "4        0.347729        0.364213        0.462478        0.281361   \n",
       "\n",
       "   mean_test_R2  std_test_R2  rank_test_R2  split0_test_RMSE  \\\n",
       "0      0.353999     0.045078             5        218.857763   \n",
       "1      0.364649     0.052834             3        219.344810   \n",
       "2      0.364649     0.052834             3        219.344810   \n",
       "3      0.366040     0.057937             1        221.906999   \n",
       "4      0.366040     0.057937             1        221.906999   \n",
       "\n",
       "   split1_test_RMSE  split2_test_RMSE  split3_test_RMSE  split4_test_RMSE  \\\n",
       "0        202.872119        214.599349         217.26014        210.338380   \n",
       "1        196.725063        207.829268         211.93851        208.326349   \n",
       "2        196.725063        207.829268         211.93851        208.326349   \n",
       "3        195.940848        203.833257         209.39840        209.540373   \n",
       "4        195.940848        203.833257         209.39840        209.540373   \n",
       "\n",
       "   split5_test_RMSE  split6_test_RMSE  split7_test_RMSE  split8_test_RMSE  \\\n",
       "0        227.303935        212.779196        222.393490        189.060568   \n",
       "1        224.745932        210.275106        217.783851        181.459855   \n",
       "2        224.745932        210.275106        217.783851        181.459855   \n",
       "3        224.083892        209.453560        217.332516        179.147244   \n",
       "4        224.083892        209.453560        217.332516        179.147244   \n",
       "\n",
       "   split9_test_RMSE  mean_test_RMSE  std_test_RMSE  rank_test_RMSE  \n",
       "0        213.893764      212.935870      10.155892               1  \n",
       "1        214.698753      209.312750      11.767846               2  \n",
       "2        214.698753      209.312750      11.767846               2  \n",
       "3        217.064631      208.770172      12.716664               4  \n",
       "4        217.064631      208.770172      12.716664               4  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'C':[2,5,10], 'degree' : [1,2,3]}\n",
    "\n",
    "scoring = {'R2': make_scorer(r2_score), 'RMSE': make_scorer(mean_squared_error)}\n",
    "\n",
    "\n",
    "clf =SVR()\n",
    "\n",
    "random_search = RandomizedSearchCV(clf, param_distributions = params, scoring=scoring, refit='R2',cv=10, iid=False,n_jobs = -1,n_iter=5)\n",
    "\n",
    "start = time.time()\n",
    "best_model = random_search.fit(X, y)\n",
    "print(\"RandomizedSearchCV took %.2f seconds to find optimal parameters.\" % (time.time() - start))\n",
    "print('Optimal Parameters found : ', best_model.best_estimator_.get_params())\n",
    "print('R2 for optimal model : ',best_model.best_score_)\n",
    "results = random_search.cv_results_\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machines RMSE : 14.19 (+/- 0.39)\n",
      "Support Vector Machines R2 Score: 0.40 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "clf = SVR(kernel = 'rbf', C=10, degree=1, gamma=0.1)\n",
    "#clf.fit(X_train,y_train)\n",
    "_,_,_,_=cross_val_scores('Support Vector Machines', clf, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN-1 RMSE : 20.77 (+/- 0.42)\n",
      "KNN-1 R2 Score: -0.29 (+/- 0.04)\n",
      "KNN-2 RMSE : 18.27 (+/- 0.31)\n",
      "KNN-2 R2 Score: -0.00 (+/- 0.02)\n",
      "KNN-3 RMSE : 17.36 (+/- 0.27)\n",
      "KNN-3 R2 Score: 0.10 (+/- 0.02)\n",
      "KNN-4 RMSE : 16.91 (+/- 0.25)\n",
      "KNN-4 R2 Score: 0.14 (+/- 0.02)\n",
      "KNN-5 RMSE : 16.57 (+/- 0.31)\n",
      "KNN-5 R2 Score: 0.18 (+/- 0.02)\n",
      "KNN-6 RMSE : 16.40 (+/- 0.32)\n",
      "KNN-6 R2 Score: 0.19 (+/- 0.02)\n",
      "KNN-7 RMSE : 16.25 (+/- 0.32)\n",
      "KNN-7 R2 Score: 0.21 (+/- 0.02)\n",
      "KNN-8 RMSE : 16.17 (+/- 0.29)\n",
      "KNN-8 R2 Score: 0.22 (+/- 0.02)\n",
      "KNN-9 RMSE : 16.12 (+/- 0.30)\n",
      "KNN-9 R2 Score: 0.22 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "rmse_scores = []\n",
    "for K in range(1,10):\n",
    "    clf = KNeighborsRegressor(n_neighbors = K)\n",
    "    _,_,rmse_val,_ = cross_val_scores('KNN-'+str(K),clf,X,y)\n",
    "    rmse_scores.append(rmse_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAHl9JREFUeJzt3XlwVPeZ7vHvK7XU2he00QgEGMwuGbDA2NiO903E2cYTe+IltifcSXwzceIklUnNzVSmJrcmE08qk1Rl4QbvDokT21mM4yWOlzgxYGFjxI7BFkighUUraP/dP7qRAQMSUnefVvfzqVKpdfrg80SBR0dv/85pc84hIiJjX5LXAUREJDxU6CIicUKFLiISJ1ToIiJxQoUuIhInVOgiInFiyEI3s0lm9rKZbTWzzWb2pdD2m0JfD5hZZeSjiojImdhQ69DNLAAEnHNvmVk2sB74OOCAAeBnwFedc9WRDisiIqfnG2oH59x+YH/ocbuZbQVKnXMvAphZZBOKiMiwDFnoxzOzKcACYO1Z/JnlwHKAzMzM82fNmnU2hxQRSXjr168/4JwrGmq/YRe6mWUBTwL3OufahvvnnHMrgBUAlZWVrrpakxkRkbNhZrXD2W9Yq1zMLIVgmT/unHtqNMFERCQyhrPKxYCVwFbn3PcjH0lEREZiOCOXpcBtQI2ZbQht+ybgB34EFAGrzWyDc+7ayMQUEZGhDGeVy+vA6ZayPB3eOCIiMlK6UlREJE6o0EVE4oQKXUQkTiRkoTe0dvHd57axr+Wo11FERMImIQv9aG8/P3llF8/W7Pc6iohI2CRkoU8tzGTuhBxWq9BFJI4kZKEDVFUEeHtPC3WHj3gdRUQkLBK30MsDAPyxpsHjJCIi4ZGwhT65IJPy0lye0dhFROJEwhY6BMcu7+xtYe8hjV1EZOxL7EIPjV202kVE4kFCF/qkcRmcNzFXq11EJC4kdKFDcOyysa6VPQc1dhGRsS3hC/2G0NhFZ+kiMtYlfKFPzM9g/qQ8Vtfs8zqKiMioJHyhAyyrCLCpvo33D3R6HUVEZMRU6MD1GruISBxQoQOleeksLMtj9UYVuoiMXSr0kKqKCWzZ38bu5g6vo4iIjIgKPeSG8vGALjISkbFLhR4SyE2ncnI+z2jsIiJjlAr9OFUVAbY1tPNuk8YuIjL2qNCPc/28AGYau4jI2KRCP8743DQWTR6n1S4iMiap0E9SVRFge2M7OxvbvY4iInJWVOgnuX7eeMx0kZGIjD0q9JMU56SxeIrGLiIy9qjQT2FZRYCdTR3s0NhFRMYQFfopXDtvPEmG1qSLyJiiQj+F4uw0LphawOqN+3DOeR1HRGRYVOinUVURYFdzJ9s1dhGRMUKFfhrXhcYuenFURMYKFfppFGb5uXBaAas37tfYRUTGBBX6GVSVT2D3gU627tfYRURi35CFbmaTzOxlM9tqZpvN7Euh7ePM7EUz2xn6nB/5uNF17dwSkpNM7zcqImPCcM7Q+4D7nHOzgSXAPWY2B/gG8JJz7lzgpdDXcaUgy89FGruIyBgxZKE75/Y7594KPW4HtgKlwMeAh0O7PQx8PFIhvVRVHuD9g0fYvK/N6ygiImd0VjN0M5sCLADWAiXOuf0QLH2g+DR/ZrmZVZtZdXNz8+jSeuDaueNJTjJdZCQiMW/YhW5mWcCTwL3OuWGfrjrnVjjnKp1zlUVFRSPJ6Kn8zFSWTi9kdY0uMhKR2DasQjezFIJl/rhz7qnQ5kYzC4SeDwBNkYnovWXlAfYeOkpNfavXUURETms4q1wMWAlsdc59/7infg/cEXp8B/C78MeLDdfMLcGXZLrISERi2nDO0JcCtwFXmNmG0McNwH8CV5vZTuDq0NdxKS8jlYvPLeQZrXYRkRjmG2oH59zrgJ3m6SvDGyd2VZUH+Nr2jbxT18r8SXlexxER+RBdKTpM18wZT0qysXqjLjISkdikQh+m3IwULjm3SBcZiUjMUqGfharyAPtau3h7b4vXUUREPkSFfhaumlNCanKSVruISExSoZ+F3PQULp1RyLM1+xkY0NhFRGKLCv0sVVUE2N/axdt7D3sdRUTkBCr0s3TV7BJSfUm6t4uIxBwV+lnKTkvhIzOKNHYRkZijQh+BZRUBGtu6Wb9HYxcRiR0q9BG4MjR20WoXEYklKvQRyPL7uHxmcOzSr7GLiMQIFfoIVVVMoKm9m+r3D3kdRUQEUKGP2JWzivH7klhdo7GLiMQGFfoIZfp9XDGrmGdrGjR2EZGYoEIfhaqKAAc6uln3nsYuIuI9FfooXDGrmLSUJFbX6Ja6IuI9FfooZKT6uHJWCc9taqCvf8DrOCKS4FTooxQcu/Ro7CIinlOhj9LlM4tJT0nmGa12ERGPqdBHKT01mStnF2vsIiKeU6GHwbKKAIc6e1izW2MXEfGOCj0MLptZTEZqsla7iIinVOhhkJaSzFWzg6tdejV2ERGPqNDDpKoiwOEjvbyx66DXUUQkQanQw+QjM4rITE3WLXVFxDMq9DBJS0nm6jklPLdZYxcR8YYKPYyWVUyg9Wgvf333gNdRRCQBqdDD6JIZhWT7fRq7iIgnVOhh5Pclc/XcEp7f3EBPn8YuIhJdKvQwW1YRoK2rT2MXEYk6FXqYXTy9iOw0H89o7CIiUaZCD7NUXxLXzh3PC1sa6O7r9zqOiCQQFXoEVFUEaO/q4/WdGruISPQMWehm9oCZNZnZpuO2nWdmb5hZjZn9wcxyIhtzbFk6rZDc9BStdhGRqBrOGfpDwHUnbfs58A3nXDnwNPC1MOca04JjlxJe3NJIV6/GLiISHUMWunPuNeDk+8LOBF4LPX4R+FSYc415VRUTaO/u4y8au4hIlIx0hr4JuDH0+CZg0ul2NLPlZlZtZtXNzc0jPNzYc9G0AvIyUli9UbfUFZHoGGmh3wXcY2brgWyg53Q7OudWOOcqnXOVRUVFIzzc2JOSnMR1c8dr7CIiUTOiQnfObXPOXeOcOx9YBewKb6z4UFURoLOnn1d3JM5vJiLinREVupkVhz4nAf8K/DScoeLFhecUkJ+h1S4iEh3DWba4CngDmGlmdWZ2N3CLme0AtgH7gAcjG3Ns8iUncd28AH/aqrGLiESeb6gdnHO3nOap/wlzlri0rCLAqnV7eGV7E9fNC3gdR0TimK4UjbALpo6jIDNV93YRkYhToUdYcOwynpe2NnG0R2MXEYkcFXoUVFUEONrbz8vbm7yOIiJxTIUeBRdMLaAwK1WrXUQkolToUZCcZFw/L8BL2xo50tPndRwRiVMq9CipqgjQ1TvAn7dp7CIikaFCj5JFU8ZRlO3X2EVEIkaFHiXJScYN88bz521NdHZr7CIi4adCj6Kqigl09w3wksYuIhIBKvQoqpycT3G2X7fUFZGIUKFHUVKScUN5gJe3N9OhsYuIhJkKPcqWVQTo6Rvgpa2NXkcRkTijQo+yhWX5jM9J071dRCTsVOhRdmzs8ur2Ztq7er2OIyJxRIXugaqKAD39A/xJYxcRCSMVugcWTMpjQm6aLjISkbBSoXvg2NjltR0HaD2qsYuIhIcK3SODY5ctGruISHio0D0yf1IepXnprK7R2EVEwkOF7hEzo6oiwF92NtN6RGMXERk9FbqHqsoD9PY7XtjS4HUUEYkDKnQPVUzMZWK+xi4iEh4qdA8dG7u8vvMALUd6vI4jImOcCt1jy8on0DfgeGGzVruIyOio0D02rzSHsnEZ/EG31BWRUVKhe8zM+LvzJ/KXnQd46K/veR1HRMYwn9cBBL5w2TRq6lv59jNbGJfl58bzJngdSUTGIJ2hxwBfchI/umUBi6aM474nNvDajmavI4nIGKRCjxFpKcn8/I5Kphdn80+PrWfD3havI4nIGKNCjyE5aSk8fOciCrJSufPBdbzb1OF1JBEZQ1ToMaY4J41H77qA5CTj9pVr2d961OtIIjJGqNBj0JTCTB66czFtXX3cvnKdLjoSkWFRoceoeaW5/L/bK6k9eIS7HnqTIz19XkcSkRinQo9hF04r4Ie3zGfD3ha+8Phb9PYPeB1JRGLYkIVuZg+YWZOZbTpu23wzW2NmG8ys2swWRzZm4rpuXoD/+Hg5r2xv5uu/2cjAgPM6kojEqOGcoT8EXHfStv8Cvu2cmw98K/S1RMg/XFDGV6+ZwdNv1/OdZ7finEpdRD5syCtFnXOvmdmUkzcDOaHHuYBuRBJh91w+nQMdPax8/T0Ks/x8/rJpXkcSkRgz0kv/7wWeN7P7CZ7lX3S6Hc1sObAcoKysbISHEzPjW8vmcKizh+8+t41xmSl8epG+nyLygZG+KPp54MvOuUnAl4GVp9vRObfCOVfpnKssKioa4eEEICnJuP+m87jk3EL+5akant+sdzoSkQ+MtNDvAJ4KPf41oBdFoyTVl8RPbz2f8ol5fHHV26zdfdDrSCISI0Za6PuAj4QeXwHsDE8cGY5Mv48HP7uISfnp/OPD1WzZ1+Z1JBGJAcNZtrgKeAOYaWZ1ZnY38Dngv83sHeD/EpqRS/SMy0zlkbsvICvNxx0PrmPPwSNeRxIRj1k0l8BVVla66urqqB0vEexsbOemn71BbnoKv/mniyjK9nsdSUTCzMzWO+cqh9pPV4qOceeWZLPyjkU0tXVzxwPraOvq9TqSiHhEhR4Hzp+cz49vXciOxnaWP1JNV2+/15FExAMq9Dhx+cxi7r/pPNbsPsS9v9xAv24RIJJwVOhx5OMLSvk/y+bw3OYG/vW3m3SLAJEEozeJjjN3XzyVgx3d/PiVXRRmpXLfNTO9jiQiUaJCj0Nfu3YmBzt6+NGf32VcZip3Lp3qdSQRiQIVehwyM77ziXkcPtLDt/+whXGZqXxsfqnXsUQkwjRDj1O+5CR+eMsCFk8dx31PvMOrO5q9jiQiEaZCj2NpKcn8/I5Kzi3J5vOPreftPYe9jiQiEaRCj3M5aSk8fNciCrP83PXQm7zb1O51JBGJEBV6AijOTuPRuxeTnJTE7SvXsa/lqNeRRCQCVOgJYnJBJg/duYj2rj5uf2Adhzt7vI4kImGmQk8g80pzWXF7JXsOHeHOh97kSE+f15FEJIxU6AnmwmkF/PDm+Wysa+Hzj71Fb/+A15FEJExU6AnounkBvvOJcl7d0czXfv0OA7rvi0hc0IVFCeqWxWUc6uzhe89vJz8zlW8tm4OZeR1LREZBhZ7AvnDZNJrbu3nwr+9TmOXnnsunex1JREZBhZ7AzIxvLZszeKZekJnKzYvLvI4lIiOkQk9wSUnG/TedR8vRXr75dA35malcO3e817FEZAT0oqiQ6kvip7cupGJiHl9c9TZrdh/0OpKIjIAKXQDISPXx4GcXUTYug889XK1SFxmDVOgyKD8zlUfuWkxOego3r1jD5x6pZkej7v0iMlao0OUEE/LSeeHLl3Lf1TNYs+sg1/3gNb7663eoO3zE62giMgSL5vtOVlZWuurq6qgdT0bnUGcPP375XR5ZUwsObrtwMvdcPp1xmaleRxNJKGa23jlXOeR+KnQZSn3LUX7w4g6efKuOjFQfyy89h7svnkqmX4ukRKJBhS5ht7Oxne89v50XtjRSmOXnn6+czs2Lykj1aXInEknDLXT9S5RhO7ckmxW3V/LUFy5iWlEm3/rdZq76/qv8bkO97gcjEgNU6HLWFpbl88vlS3jwzkVk+n186ZcbqPrR67y8vYlo/sYnIidSocuImBmXzyxm9Rcv5n9unk9ndx93Pvgmn16xhvW1eu9SES+o0GVUkpKMj80v5U9f+Qj//rG57G7u4FM/+Rufe6SanVrDLhJVelFUwqqzu48HXn+Pn722myM9fXxq4UTuvXoGpXnpXkcTGbO0ykU8NbiG/Y1aMLh9SXANe77WsIucNRW6xITj17Bnhtaw36U17CJnJWyFbmYPAMuAJufcvNC2XwEzQ7vkAS3OuflDHUyFnrh2NLZzv9awi4xIOAv9UqADeORYoZ/0/H8Drc65fx/qYCp0WV97mO8+t4117x2ibFwG910zg49WTCApSW9/J3I6YbuwyDn3GnDoNAcx4O+BVWedUBLS+ZPz+dVJa9iX/eh1XtEadpFRG+3vu5cAjc65neEII4nh5DXs7d29fPbBN7l5xRre2qM17CIjNdpCv4Uhzs7NbLmZVZtZdXNz8ygPJ/Hk2Br2l75yGd++cS67mjv45I//xvJHqnm3SWvYRc7WsFa5mNkU4JnjZ+hm5gPqgfOdc3XDOZhm6HImnd19rHz9PVaE1rD/3fkTufeqGUzQGnZJcNG4OddVwLbhlrnIUDL9Pv75ynN57euXc+fSqfz27X1cdv8r/MczW6hvOep1PJGYN5xVLquAy4BCoBH4N+fcSjN7CFjjnPvpcA+mM3Q5G8evYQe4YlYJt104mUumF2pVjCQUXVgkcaO+5Sir1u7hl2/u4UBHD5MLMvjMBWXcdP4kXXkqCUGFLnGnp2+A5zY38Ngbtax7/xCpviQ+WjGBW5eUMX9SHsFVtCLxR4UucW17QzuPranlqbfq6OzpZ15pDrctmcyN55WSnprsdTyRsFKhS0Lo6O7j6bfreeyNWrY3tpOT5uNT50/k1iWTmVaU5XU8kbBQoUtCcc5RXXuYR9+o5Y+b9tPb71g6vYDblkzmqtkl+JJ1zxgZu1TokrCa27t5onovv1i7h/qWo5Tk+LllcRm3LC6jJCfN63giZ02FLgmvf8Dx8rYmHl1Ty6s7mklOMq6dW8KtSyZz4TkFehFVxozhFrpuSi1xKznJuGpOCVfNKaH2YCe/WLuHX1Xv5dmaBqYVZXLrksl8cuFEctNTvI4qEhY6Q5eE0tXbz+qN+3l0TS0b9raQnpLMxxdM4DMXTGZeaa7X8UROSSMXkSFsqm/lsTW1/HZDPV29Aywoy+O2JZO5oTxAWoqWPkrsUKGLDFPr0V6eXF/HY2tr2d3cSX5GCn9fOYnPXDCZsoIMr+OJqNBFzpZzjjd2HeTRNbW8sKWRAef4yIwiblsymctmFpOs+8eIR1ToIqPQ0NrFqnXB+8c0tnVTmpfOP1xQxqcXTaIwy+91PEkwKnSRMOjtH+BPWxp5dE0tf9t1kJRk4+LphZw3KY/y0lzKJ+ZSnK217RJZWrYoEgYpyUlcXx7g+vIA7zZ18PjaWl7feYBXdjRz7FxofE4a80pzqZgYLPjy0lydxYsnVOgiwzS9OIt/++hcIPjuSpv3tVFT30pNXQsb61t5aVvjYMlPyE0bLPfyicGz+XG61a9EmApdZAQy/T4WTx3H4qnjBre1d/UGS76uNVj09a08v7lx8PnSvPQTzuLLS3PJy1DJS/io0EXCJDsthSXnFLDknILBba1He9m8r5WaulY21reyqb6VP25qGHy+bFzG4Cy+ojSXuaW5unJVRkyFLhJBuekpXDStkIumFQ5uaz3Sy6Z9rWysa6WmvoWN9S2srtk/+PyUgozQmCaH8tI85pXmkJ2mkpehqdBFoiw3I4Wl0wtZOv2Dkj/c2TM4pqmpa+Wt2sP84Z19g8+fU5h5wqhmbmkuWX7985UT6W+ESAzIz0zl0hlFXDqjaHDbwY7uwYKvqW9l3XuH+N2GYMmbwbSiLMpLc5kTyGFWIJtZ43MoytbqmkSmdegiY0hzezeb6o+Na4Ijm8a27sHnC7NSmTU+h9mhgp8VyGZ6cRZ+n+5NM5ZpHbpIHCrK9nP5rGIun1U8uO1QZw/bGtrYtr+dbQ1tbN3fziNv1NLdNwAEbyM8rShzsOBnhz6Pz0nTPeHjjApdZIwbl5n6oRde+/oHeP/gkROKfn3tYX5/3Fw+Nz2FWeOzmR3IYdb4bGYFcphRkkVGqmphrNL/cyJxyJecxPTiLKYXZ7Gs4oPtrUd72dHYzrb9bWxtCH5+onovR3r6geBsfmpB5uBM/ljhl+alk6Sbk8U8FbpIAslNT2HRlHEsmvLBBVEDA466w0fZsr9t8Ix+y742/ripYfDK1yy/j5njswfP5GePz2bm+Gwtp4wxelFURE6ps7sveDbfcOIZfVtX3+A+E/PTT3gR9tySLEqy08hJ92k+H0Z6UVRERiXT72NBWT4LyvIHtznn2N/axdb9bWxraB/8/OdtjQwcd26Y6kuiONtPUbaf4mw/xdlpHzzO+eDrgsxUfMlJHvyvi08qdBEZNjNjQl46E/LSuXJ2yeD2rt5+3m3qYFdzB83t3TS3d9PU3k1Texe7mztZ+94hWo70nuK/BwWZxxd/sPCLsvwU56Qd90MhjfRULb0cigpdREYtLSWZeaW5Z3yj7e6+/pPKvpvmti6aO7ppagt+vb2hneaObvoHPjwKzvb7KDpW8CeU/Ym/AeRlpCTsuEeFLiJR4fclMzE/g4n5Z36f1oEBx6EjPR8Uf1tXsPwHfxh0UVPXQlN79+DqnOOlJidRlO2nMNtPfkYKWX7fBx9pQz/O9PtIGaNjIBW6iMSUpCSjMMtPYZaf2YEz79vR3UdTW9eJZ/2h0m9u7+ZQZw97Dh6ho7uPju6+U/4AOJW0lCSy/Clk+ZNPLP5Q+Wf6fWQPfh3az58S2veDxxkpyVFd7qlCF5ExK8vvI6soi3OKsoa1f/+Ao7Onj46uYMG3d/XRGSr7Y9uOfZz83L6Wrg+e7+qjp39gyOOZQWbqsTP/ZL5303ksPO5F5nBToYtIwkhOMnLSUsgJw/r57r5+Orv7T/pB0Bv6QdBPR3dv6LnQ4+4+siN8h0wVuojICPh9yfh9yTH11oJDTv7N7AEzazKzTSdt/6KZbTezzWb2X5GLKCIiwzGcl3IfAq47foOZXQ58DKhwzs0F7g9/NBERORtDFrpz7jXg0EmbPw/8p3OuO7RPUwSyiYjIWRjpYssZwCVmttbMXjWzRafb0cyWm1m1mVU3NzeP8HAiIjKUkRa6D8gHlgBfA56w01ya5Zxb4ZyrdM5VFhUVnWoXEREJg5EWeh3wlAtaBwwAhUP8GRERiaCRFvpvgSsAzGwGkAocCFcoERE5e0OuQzezVcBlQKGZ1QH/BjwAPBBaytgD3OGieWN1ERH5kKi+wYWZtQPbo3bAoRUSO79ZxFIWiK08sZQFlOdMYikLxE+eyc65IV+EjPaVotuH864b0WJm1bGSJ5ayQGzliaUsoDxnEktZIPHyjM17RIqIyIeo0EVE4kS0C31FlI83lFjKE0tZILbyxFIWUJ4ziaUskGB5ovqiqIiIRI5GLiIicUKFLiISJ6JS6GZ2Xeje6e+a2Teiccwh8pzyHu8eZZlkZi+b2dbQveW/5GGWNDNbZ2bvhLJ826ssxzOzZDN728yeiYEs75tZjZltMLNqj7PkmdlvzGxb6O/PhR5mmRn6nhz7aDOzez3M8+XQ3+FNZrbKzNK8yhLK86VQls0R/b445yL6ASQDu4BzCN4i4B1gTqSPO0SmS4GFwCYvc4SyBICFocfZwA6vvj+AAVmhxynAWmBJDHyPvgL8AngmBrK8DxR6nSOU5WHgH0OPU4E8rzOFsiQDDQQvhvHi+KXAe0B66OsngM96+P2YB2wCMghe+/Mn4NxIHCsaZ+iLgXedc7udcz3ALwm+OYZn3Knv8e4J59x+59xbocftwFaCfyG9yOKccx2hL1NCH56+am5mE4Eq4Ode5og1ZpZD8MRkJYBzrsc51+JtqkFXArucc7UeZvAB6WbmI1ik+zzMMhtY45w74pzrA14FPhGJA0Wj0EuBvcd9XYdHhRXrzGwKsIDgmbFXGZLNbAPQBLzonPMsS8gPgK8TvKNnLHDAC2a23syWe5jjHKAZeDA0jvq5mWV6mOd4NwOrvDq4c66e4Luo7QH2A63OuRe8ykPw7PxSMyswswzgBmBSJA4UjUI/1X3StVbyJGaWBTwJ3Ouca/Mqh3Ou3zk3H5gILDazeV5lMbNlQJNzbr1XGU5hqXNuIXA9cI+ZXepRDh/BseFPnHMLgE4gFl6fSgVuBH7tYYZ8glOAqcAEINPMbvUqj3NuK/Bd4EXgOYJj575IHCsahV7HiT+NJuLtrz8xx8xSCJb54865p7zOAxD69f0VTno/2ShbCtxoZu8THNVdYWaPeZgH59y+0Ocm4GmCI0Uv1AF1x/0G9RuCBe+164G3nHONHma4CnjPOdfsnOsFngIu8jAPzrmVzrmFzrlLCY57d0biONEo9DeBc81sauin983A76Nw3DEh9E5PK4Gtzrnve5ylyMzyQo/TCf7D2OZVHufcvzjnJjrnphD8e/Nn55xnZ1pmlmlm2cceA9cQ/HU66pxzDcBeM5sZ2nQlsMWLLCe5BQ/HLSF7gCVmlhH693UlwdemPGNmxaHPZcAnidD3KOJ3W3TO9ZnZ/waeJ/jq9wPOuc2RPu6ZnOoe7865lR7FWQrcBtSEZtcA33TOPetBlgDwsJklE/xh/4RzzvOlgjGkBHg69G6LPuAXzrnnPMzzReDx0InSbuBOD7MQmg9fDfwvL3M459aa2W+AtwiONt7G+1sAPGlmBUAvcI9z7nAkDqJL/0VE4oSuFBURiRMqdBGROKFCFxGJEyp0EZE4oUIXEYkTKnQRkTihQhcRiRP/H+/KsDVukAduAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting the rmse values against k values\n",
    "curve = pd.DataFrame(rmse_scores) #elbow curve \n",
    "\n",
    "plt.plot(np.arange(1,10),curve)\n",
    "plt.xticks(np.arange(0,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN-9 RMSE : 16.12 (+/- 0.30)\n",
      "KNN-9 R2 Score: 0.22 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "K = 9\n",
    "clf = KNeighborsRegressor(n_neighbors = K,n_jobs=-1)\n",
    "_,r2_scores,_,_ = cross_val_scores('KNN-'+str(K),clf,X,y,cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 131.97 seconds to find optimal parameters.\n",
      "Optimal Parameters found :  {'Cs': None, 'cv': 3, 'exp_rand_tree_size': True, 'lin_standardise': True, 'lin_trim_quantile': 0.025, 'max_rules': 200, 'memory_par': 0.01, 'model_type': 'rl', 'random_state': 1, 'rfmode': 'regress', 'sample_fract': 'default', 'tree_generator__alpha': 0.9, 'tree_generator__criterion': 'friedman_mse', 'tree_generator__init': None, 'tree_generator__learning_rate': 0.01, 'tree_generator__loss': 'ls', 'tree_generator__max_depth': 100, 'tree_generator__max_features': None, 'tree_generator__max_leaf_nodes': 4, 'tree_generator__min_impurity_decrease': 0.0, 'tree_generator__min_impurity_split': None, 'tree_generator__min_samples_leaf': 1, 'tree_generator__min_samples_split': 2, 'tree_generator__min_weight_fraction_leaf': 0.0, 'tree_generator__n_estimators': 60, 'tree_generator__n_iter_no_change': None, 'tree_generator__presort': 'auto', 'tree_generator__random_state': 60, 'tree_generator__subsample': 0.06658830877219045, 'tree_generator__tol': 0.0001, 'tree_generator__validation_fraction': 0.1, 'tree_generator__verbose': 0, 'tree_generator__warm_start': False, 'tree_generator': GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "                          learning_rate=0.01, loss='ls', max_depth=100,\n",
      "                          max_features=None, max_leaf_nodes=4,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=60,\n",
      "                          n_iter_no_change=None, presort='auto',\n",
      "                          random_state=60, subsample=0.06658830877219045,\n",
      "                          tol=0.0001, validation_fraction=0.1, verbose=0,\n",
      "                          warm_start=False), 'tree_size': 4}\n",
      "R2 for optimal model :  0.3727012584430669\n"
     ]
    }
   ],
   "source": [
    "params = {\"tree_size\": [2,4,6], \n",
    "              \"max_rules\" : [100,200]}\n",
    "\n",
    "scoring = {'R2': make_scorer(r2_score), 'RMSE': make_scorer(mean_squared_error)}\n",
    "\n",
    "rf = RuleFit(memory_par=0.01,\n",
    "             tree_generator=None,\n",
    "            rfmode='regress',random_state=1) \n",
    "\n",
    "grid_search = GridSearchCV(rf, param_grid = params, scoring=scoring, refit='R2',cv=10, iid=False,n_jobs = -1)\n",
    "\n",
    "start = time.time()\n",
    "best_model = grid_search.fit(X, y)\n",
    "print(\"RandomizedSearchCV took %.2f seconds to find optimal parameters.\" % (time.time() - start))\n",
    "print('Optimal Parameters found : ', best_model.best_estimator_.get_params())\n",
    "print('R2 for optimal model : ',best_model.best_score_)\n",
    "results = pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'R2': make_scorer(r2_score), 'RMSE': make_scorer(mean_squared_error)}\n",
    "\n",
    "rf = RuleFit(memory_par=0.01, tree_size=4, tree_generator=None, max_rules=100,rfmode='regress',random_state=1) \n",
    "result_cross_val = pd.DataFrame(cross_validate(rf.fit(X, y), X, y, cv=10, scoring=scoring))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RuleFit RMSE : 14.38 (+/- 0.41)\n",
      "RuleFit R2 Score: 0.37 (+/- 0.05)\n"
     ]
    }
   ],
   "source": [
    "mean_rmse = np.sqrt(np.array(result_cross_val['test_RMSE'])).mean()\n",
    "std_rmse =  np.sqrt(np.array(result_cross_val['test_RMSE'])).std()\n",
    "print(\"%s RMSE : %0.2f (+/- %0.2f)\" % ('RuleFit', mean_rmse, std_rmse))\n",
    "\n",
    "mean_r2 = np.array(result_cross_val['test_R2']).mean()\n",
    "std_r2 =  np.array(result_cross_val['test_R2']).std()\n",
    "print(\"%s R2 Score: %0.2f (+/- %0.2f)\" % ('RuleFit', mean_r2, std_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rule</th>\n",
       "      <th>type</th>\n",
       "      <th>coef</th>\n",
       "      <th>support</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>feature_31 &gt; 0.06310335360467434 &amp; feature_16 ...</td>\n",
       "      <td>rule</td>\n",
       "      <td>0.204506</td>\n",
       "      <td>0.005510</td>\n",
       "      <td>0.015138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>feature_16 &gt; -0.009102161973714828 &amp; feature_2...</td>\n",
       "      <td>rule</td>\n",
       "      <td>2.139610</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>0.261365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>feature_16 &lt;= -0.01812302228063345 &amp; feature_3...</td>\n",
       "      <td>rule</td>\n",
       "      <td>0.332955</td>\n",
       "      <td>0.022039</td>\n",
       "      <td>0.048881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>feature_16 &lt;= 0.043494511395692825 &amp; feature_5...</td>\n",
       "      <td>rule</td>\n",
       "      <td>-2.065415</td>\n",
       "      <td>0.023416</td>\n",
       "      <td>0.312333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>feature_16 &gt; -0.03653703257441521 &amp; feature_8 ...</td>\n",
       "      <td>rule</td>\n",
       "      <td>2.009849</td>\n",
       "      <td>0.042700</td>\n",
       "      <td>0.406350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  rule  type      coef  \\\n",
       "50   feature_31 > 0.06310335360467434 & feature_16 ...  rule  0.204506   \n",
       "105  feature_16 > -0.009102161973714828 & feature_2...  rule  2.139610   \n",
       "55   feature_16 <= -0.01812302228063345 & feature_3...  rule  0.332955   \n",
       "47   feature_16 <= 0.043494511395692825 & feature_5...  rule -2.065415   \n",
       "135  feature_16 > -0.03653703257441521 & feature_8 ...  rule  2.009849   \n",
       "\n",
       "      support  importance  \n",
       "50   0.005510    0.015138  \n",
       "105  0.015152    0.261365  \n",
       "55   0.022039    0.048881  \n",
       "47   0.023416    0.312333  \n",
       "135  0.042700    0.406350  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules = pd.DataFrame(rf.get_rules())\n",
    "rules = rules[rules.coef != 0].sort_values(by=\"support\")\n",
    "num_rules_rule=len(rules[rules.type=='rule'])\n",
    "num_rules_linear=len(rules[rules.type=='linear'])\n",
    "rules.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 438.64 seconds to find optimal parameters.\n",
      "Optimal Parameters found :  {'bootstrap': True, 'criterion': 'mse', 'max_depth': 10, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 300, 'n_jobs': -1, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n",
      "R2 for optimal model :  0.38152431415719257\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_R2</th>\n",
       "      <th>split1_test_R2</th>\n",
       "      <th>split2_test_R2</th>\n",
       "      <th>split3_test_R2</th>\n",
       "      <th>split4_test_R2</th>\n",
       "      <th>split5_test_R2</th>\n",
       "      <th>split6_test_R2</th>\n",
       "      <th>split7_test_R2</th>\n",
       "      <th>split8_test_R2</th>\n",
       "      <th>split9_test_R2</th>\n",
       "      <th>mean_test_R2</th>\n",
       "      <th>std_test_R2</th>\n",
       "      <th>rank_test_R2</th>\n",
       "      <th>split0_test_RMSE</th>\n",
       "      <th>split1_test_RMSE</th>\n",
       "      <th>split2_test_RMSE</th>\n",
       "      <th>split3_test_RMSE</th>\n",
       "      <th>split4_test_RMSE</th>\n",
       "      <th>split5_test_RMSE</th>\n",
       "      <th>split6_test_RMSE</th>\n",
       "      <th>split7_test_RMSE</th>\n",
       "      <th>split8_test_RMSE</th>\n",
       "      <th>split9_test_RMSE</th>\n",
       "      <th>mean_test_RMSE</th>\n",
       "      <th>std_test_RMSE</th>\n",
       "      <th>rank_test_RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77.789608</td>\n",
       "      <td>2.148149</td>\n",
       "      <td>2.326581</td>\n",
       "      <td>2.027437</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'n_estimators': 300, 'min_samples_split': 5, ...</td>\n",
       "      <td>0.290413</td>\n",
       "      <td>0.425665</td>\n",
       "      <td>0.419432</td>\n",
       "      <td>0.414117</td>\n",
       "      <td>0.388783</td>\n",
       "      <td>0.391297</td>\n",
       "      <td>0.394093</td>\n",
       "      <td>0.380035</td>\n",
       "      <td>0.435168</td>\n",
       "      <td>0.276240</td>\n",
       "      <td>0.381524</td>\n",
       "      <td>0.051981</td>\n",
       "      <td>1</td>\n",
       "      <td>212.513489</td>\n",
       "      <td>193.127458</td>\n",
       "      <td>200.041500</td>\n",
       "      <td>202.839912</td>\n",
       "      <td>201.547455</td>\n",
       "      <td>213.167488</td>\n",
       "      <td>194.565298</td>\n",
       "      <td>211.924227</td>\n",
       "      <td>188.249177</td>\n",
       "      <td>218.611341</td>\n",
       "      <td>203.658734</td>\n",
       "      <td>9.539324</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77.166804</td>\n",
       "      <td>2.025920</td>\n",
       "      <td>4.530310</td>\n",
       "      <td>3.275493</td>\n",
       "      <td>300</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'n_estimators': 300, 'min_samples_split': 10,...</td>\n",
       "      <td>0.290641</td>\n",
       "      <td>0.425619</td>\n",
       "      <td>0.417732</td>\n",
       "      <td>0.413768</td>\n",
       "      <td>0.388364</td>\n",
       "      <td>0.391075</td>\n",
       "      <td>0.394901</td>\n",
       "      <td>0.380212</td>\n",
       "      <td>0.434316</td>\n",
       "      <td>0.276514</td>\n",
       "      <td>0.381314</td>\n",
       "      <td>0.051660</td>\n",
       "      <td>2</td>\n",
       "      <td>212.445045</td>\n",
       "      <td>193.143069</td>\n",
       "      <td>200.627540</td>\n",
       "      <td>202.960757</td>\n",
       "      <td>201.685791</td>\n",
       "      <td>213.245006</td>\n",
       "      <td>194.305859</td>\n",
       "      <td>211.863668</td>\n",
       "      <td>188.533096</td>\n",
       "      <td>218.528667</td>\n",
       "      <td>203.733850</td>\n",
       "      <td>9.475672</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106.511946</td>\n",
       "      <td>5.186230</td>\n",
       "      <td>7.687943</td>\n",
       "      <td>1.299159</td>\n",
       "      <td>300</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>{'n_estimators': 300, 'min_samples_split': 2, ...</td>\n",
       "      <td>0.288411</td>\n",
       "      <td>0.403320</td>\n",
       "      <td>0.411084</td>\n",
       "      <td>0.417762</td>\n",
       "      <td>0.381022</td>\n",
       "      <td>0.396908</td>\n",
       "      <td>0.393231</td>\n",
       "      <td>0.367392</td>\n",
       "      <td>0.431506</td>\n",
       "      <td>0.283215</td>\n",
       "      <td>0.377385</td>\n",
       "      <td>0.048885</td>\n",
       "      <td>5</td>\n",
       "      <td>213.113128</td>\n",
       "      <td>200.641252</td>\n",
       "      <td>202.918150</td>\n",
       "      <td>201.578017</td>\n",
       "      <td>204.106796</td>\n",
       "      <td>211.202197</td>\n",
       "      <td>194.842226</td>\n",
       "      <td>216.245767</td>\n",
       "      <td>189.469677</td>\n",
       "      <td>216.504439</td>\n",
       "      <td>205.062165</td>\n",
       "      <td>8.621385</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.543653</td>\n",
       "      <td>4.880678</td>\n",
       "      <td>9.425044</td>\n",
       "      <td>3.572937</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'n_estimators': 100, 'min_samples_split': 10,...</td>\n",
       "      <td>0.288175</td>\n",
       "      <td>0.425199</td>\n",
       "      <td>0.417428</td>\n",
       "      <td>0.411652</td>\n",
       "      <td>0.387145</td>\n",
       "      <td>0.392592</td>\n",
       "      <td>0.395821</td>\n",
       "      <td>0.379426</td>\n",
       "      <td>0.429909</td>\n",
       "      <td>0.267906</td>\n",
       "      <td>0.379525</td>\n",
       "      <td>0.053284</td>\n",
       "      <td>4</td>\n",
       "      <td>213.183726</td>\n",
       "      <td>193.284152</td>\n",
       "      <td>200.732123</td>\n",
       "      <td>203.693454</td>\n",
       "      <td>202.087633</td>\n",
       "      <td>212.713830</td>\n",
       "      <td>194.010650</td>\n",
       "      <td>212.132335</td>\n",
       "      <td>190.001915</td>\n",
       "      <td>221.128457</td>\n",
       "      <td>204.296828</td>\n",
       "      <td>9.715465</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.352216</td>\n",
       "      <td>3.457810</td>\n",
       "      <td>4.527773</td>\n",
       "      <td>2.433384</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'n_estimators': 100, 'min_samples_split': 5, ...</td>\n",
       "      <td>0.287987</td>\n",
       "      <td>0.425507</td>\n",
       "      <td>0.418232</td>\n",
       "      <td>0.411960</td>\n",
       "      <td>0.387668</td>\n",
       "      <td>0.392612</td>\n",
       "      <td>0.395241</td>\n",
       "      <td>0.379255</td>\n",
       "      <td>0.430261</td>\n",
       "      <td>0.266928</td>\n",
       "      <td>0.379565</td>\n",
       "      <td>0.053648</td>\n",
       "      <td>3</td>\n",
       "      <td>213.240028</td>\n",
       "      <td>193.180664</td>\n",
       "      <td>200.455076</td>\n",
       "      <td>203.586830</td>\n",
       "      <td>201.915310</td>\n",
       "      <td>212.706967</td>\n",
       "      <td>194.196751</td>\n",
       "      <td>212.190864</td>\n",
       "      <td>189.884626</td>\n",
       "      <td>221.423982</td>\n",
       "      <td>204.278110</td>\n",
       "      <td>9.800969</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      77.789608      2.148149         2.326581        2.027437   \n",
       "1      77.166804      2.025920         4.530310        3.275493   \n",
       "2     106.511946      5.186230         7.687943        1.299159   \n",
       "3      25.543653      4.880678         9.425044        3.572937   \n",
       "4      17.352216      3.457810         4.527773        2.433384   \n",
       "\n",
       "  param_n_estimators param_min_samples_split param_max_depth  \\\n",
       "0                300                       5              10   \n",
       "1                300                      10              10   \n",
       "2                300                       2            None   \n",
       "3                100                      10              10   \n",
       "4                100                       5              10   \n",
       "\n",
       "                                              params  split0_test_R2  \\\n",
       "0  {'n_estimators': 300, 'min_samples_split': 5, ...        0.290413   \n",
       "1  {'n_estimators': 300, 'min_samples_split': 10,...        0.290641   \n",
       "2  {'n_estimators': 300, 'min_samples_split': 2, ...        0.288411   \n",
       "3  {'n_estimators': 100, 'min_samples_split': 10,...        0.288175   \n",
       "4  {'n_estimators': 100, 'min_samples_split': 5, ...        0.287987   \n",
       "\n",
       "   split1_test_R2  split2_test_R2  split3_test_R2  split4_test_R2  \\\n",
       "0        0.425665        0.419432        0.414117        0.388783   \n",
       "1        0.425619        0.417732        0.413768        0.388364   \n",
       "2        0.403320        0.411084        0.417762        0.381022   \n",
       "3        0.425199        0.417428        0.411652        0.387145   \n",
       "4        0.425507        0.418232        0.411960        0.387668   \n",
       "\n",
       "   split5_test_R2  split6_test_R2  split7_test_R2  split8_test_R2  \\\n",
       "0        0.391297        0.394093        0.380035        0.435168   \n",
       "1        0.391075        0.394901        0.380212        0.434316   \n",
       "2        0.396908        0.393231        0.367392        0.431506   \n",
       "3        0.392592        0.395821        0.379426        0.429909   \n",
       "4        0.392612        0.395241        0.379255        0.430261   \n",
       "\n",
       "   split9_test_R2  mean_test_R2  std_test_R2  rank_test_R2  split0_test_RMSE  \\\n",
       "0        0.276240      0.381524     0.051981             1        212.513489   \n",
       "1        0.276514      0.381314     0.051660             2        212.445045   \n",
       "2        0.283215      0.377385     0.048885             5        213.113128   \n",
       "3        0.267906      0.379525     0.053284             4        213.183726   \n",
       "4        0.266928      0.379565     0.053648             3        213.240028   \n",
       "\n",
       "   split1_test_RMSE  split2_test_RMSE  split3_test_RMSE  split4_test_RMSE  \\\n",
       "0        193.127458        200.041500        202.839912        201.547455   \n",
       "1        193.143069        200.627540        202.960757        201.685791   \n",
       "2        200.641252        202.918150        201.578017        204.106796   \n",
       "3        193.284152        200.732123        203.693454        202.087633   \n",
       "4        193.180664        200.455076        203.586830        201.915310   \n",
       "\n",
       "   split5_test_RMSE  split6_test_RMSE  split7_test_RMSE  split8_test_RMSE  \\\n",
       "0        213.167488        194.565298        211.924227        188.249177   \n",
       "1        213.245006        194.305859        211.863668        188.533096   \n",
       "2        211.202197        194.842226        216.245767        189.469677   \n",
       "3        212.713830        194.010650        212.132335        190.001915   \n",
       "4        212.706967        194.196751        212.190864        189.884626   \n",
       "\n",
       "   split9_test_RMSE  mean_test_RMSE  std_test_RMSE  rank_test_RMSE  \n",
       "0        218.611341      203.658734       9.539324               5  \n",
       "1        218.528667      203.733850       9.475672               4  \n",
       "2        216.504439      205.062165       8.621385               1  \n",
       "3        221.128457      204.296828       9.715465               2  \n",
       "4        221.423982      204.278110       9.800969               3  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\"n_estimators\": [100,300], \n",
    "              \"max_depth\" : [None,2,10],\n",
    "              \"min_samples_split\" : [2,5,10]}\n",
    "\n",
    "scoring = {'R2': make_scorer(r2_score), 'RMSE': make_scorer(mean_squared_error)}\n",
    "\n",
    "\n",
    "clf =RandomForestRegressor(random_state=0, n_jobs = -1)\n",
    "\n",
    "random_search = RandomizedSearchCV(clf, param_distributions = params, scoring=scoring, refit='R2',cv=10, iid=False,n_jobs = -1,n_iter=5)\n",
    "\n",
    "start = time.time()\n",
    "best_model = random_search.fit(X, y)\n",
    "print(\"RandomizedSearchCV took %.2f seconds to find optimal parameters.\" % (time.time() - start))\n",
    "print('Optimal Parameters found : ', best_model.best_estimator_.get_params())\n",
    "print('R2 for optimal model : ',best_model.best_score_)\n",
    "results = random_search.cv_results_\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF RMSE : 13.96 (+/- 0.42)\n",
      "RF R2 Score: 0.42 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestRegressor(max_depth=None,n_estimators=300,min_samples_split=5,n_jobs=-1)\n",
    "_,r2_scores,_,_ = cross_val_scores('RF',clf,X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV took 223.99 seconds to find optimal parameters.\n",
      "Optimal Parameters found :  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.02, 'max_depth': 8, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}\n",
      "R2 for optimal model :  0.3952456828319076\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_R2</th>\n",
       "      <th>split1_test_R2</th>\n",
       "      <th>split2_test_R2</th>\n",
       "      <th>split3_test_R2</th>\n",
       "      <th>split4_test_R2</th>\n",
       "      <th>split5_test_R2</th>\n",
       "      <th>split6_test_R2</th>\n",
       "      <th>split7_test_R2</th>\n",
       "      <th>split8_test_R2</th>\n",
       "      <th>split9_test_R2</th>\n",
       "      <th>mean_test_R2</th>\n",
       "      <th>std_test_R2</th>\n",
       "      <th>rank_test_R2</th>\n",
       "      <th>split0_test_RMSE</th>\n",
       "      <th>split1_test_RMSE</th>\n",
       "      <th>split2_test_RMSE</th>\n",
       "      <th>split3_test_RMSE</th>\n",
       "      <th>split4_test_RMSE</th>\n",
       "      <th>split5_test_RMSE</th>\n",
       "      <th>split6_test_RMSE</th>\n",
       "      <th>split7_test_RMSE</th>\n",
       "      <th>split8_test_RMSE</th>\n",
       "      <th>split9_test_RMSE</th>\n",
       "      <th>mean_test_RMSE</th>\n",
       "      <th>std_test_RMSE</th>\n",
       "      <th>rank_test_RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.857841</td>\n",
       "      <td>0.938545</td>\n",
       "      <td>0.103105</td>\n",
       "      <td>0.032921</td>\n",
       "      <td>300</td>\n",
       "      <td>9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'n_estimators': 300, 'max_depth': 9, 'learnin...</td>\n",
       "      <td>0.288668</td>\n",
       "      <td>0.428440</td>\n",
       "      <td>0.418761</td>\n",
       "      <td>0.410989</td>\n",
       "      <td>0.387559</td>\n",
       "      <td>0.383922</td>\n",
       "      <td>0.391160</td>\n",
       "      <td>0.384391</td>\n",
       "      <td>0.435925</td>\n",
       "      <td>0.290610</td>\n",
       "      <td>0.382042</td>\n",
       "      <td>0.049440</td>\n",
       "      <td>5</td>\n",
       "      <td>213.036175</td>\n",
       "      <td>192.194579</td>\n",
       "      <td>200.272843</td>\n",
       "      <td>203.922917</td>\n",
       "      <td>201.951148</td>\n",
       "      <td>215.750184</td>\n",
       "      <td>195.507263</td>\n",
       "      <td>210.435137</td>\n",
       "      <td>187.996662</td>\n",
       "      <td>214.270776</td>\n",
       "      <td>203.533768</td>\n",
       "      <td>9.220316</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.262346</td>\n",
       "      <td>1.107602</td>\n",
       "      <td>0.076558</td>\n",
       "      <td>0.027454</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 10, 'learni...</td>\n",
       "      <td>0.284622</td>\n",
       "      <td>0.412311</td>\n",
       "      <td>0.391301</td>\n",
       "      <td>0.389452</td>\n",
       "      <td>0.374834</td>\n",
       "      <td>0.362345</td>\n",
       "      <td>0.375417</td>\n",
       "      <td>0.371609</td>\n",
       "      <td>0.411402</td>\n",
       "      <td>0.284755</td>\n",
       "      <td>0.365805</td>\n",
       "      <td>0.043394</td>\n",
       "      <td>7</td>\n",
       "      <td>214.247793</td>\n",
       "      <td>197.617869</td>\n",
       "      <td>209.734531</td>\n",
       "      <td>211.379402</td>\n",
       "      <td>206.147170</td>\n",
       "      <td>223.306342</td>\n",
       "      <td>200.562374</td>\n",
       "      <td>214.804439</td>\n",
       "      <td>196.169768</td>\n",
       "      <td>216.039366</td>\n",
       "      <td>209.000906</td>\n",
       "      <td>8.337601</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.244082</td>\n",
       "      <td>0.798453</td>\n",
       "      <td>0.062480</td>\n",
       "      <td>0.018483</td>\n",
       "      <td>200</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': None, 'lear...</td>\n",
       "      <td>0.272439</td>\n",
       "      <td>0.431204</td>\n",
       "      <td>0.453371</td>\n",
       "      <td>0.417627</td>\n",
       "      <td>0.370276</td>\n",
       "      <td>0.382572</td>\n",
       "      <td>0.387557</td>\n",
       "      <td>0.368708</td>\n",
       "      <td>0.423840</td>\n",
       "      <td>0.287589</td>\n",
       "      <td>0.379518</td>\n",
       "      <td>0.056334</td>\n",
       "      <td>6</td>\n",
       "      <td>217.896575</td>\n",
       "      <td>191.265128</td>\n",
       "      <td>188.347678</td>\n",
       "      <td>201.624713</td>\n",
       "      <td>207.650037</td>\n",
       "      <td>216.222697</td>\n",
       "      <td>196.664084</td>\n",
       "      <td>215.795870</td>\n",
       "      <td>192.024370</td>\n",
       "      <td>215.183305</td>\n",
       "      <td>204.267446</td>\n",
       "      <td>11.087700</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.466842</td>\n",
       "      <td>0.311525</td>\n",
       "      <td>0.028118</td>\n",
       "      <td>0.015307</td>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 3, 'learnin...</td>\n",
       "      <td>-0.056891</td>\n",
       "      <td>-0.037068</td>\n",
       "      <td>-0.031228</td>\n",
       "      <td>-0.027724</td>\n",
       "      <td>-0.027218</td>\n",
       "      <td>-0.040343</td>\n",
       "      <td>-0.009783</td>\n",
       "      <td>-0.022472</td>\n",
       "      <td>-0.054521</td>\n",
       "      <td>-0.037243</td>\n",
       "      <td>-0.034449</td>\n",
       "      <td>0.013475</td>\n",
       "      <td>10</td>\n",
       "      <td>316.527214</td>\n",
       "      <td>348.727433</td>\n",
       "      <td>355.322077</td>\n",
       "      <td>355.810792</td>\n",
       "      <td>338.722836</td>\n",
       "      <td>364.327461</td>\n",
       "      <td>324.255831</td>\n",
       "      <td>349.513858</td>\n",
       "      <td>351.454233</td>\n",
       "      <td>313.298658</td>\n",
       "      <td>341.796039</td>\n",
       "      <td>16.898637</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.243151</td>\n",
       "      <td>0.953824</td>\n",
       "      <td>0.085642</td>\n",
       "      <td>0.009882</td>\n",
       "      <td>300</td>\n",
       "      <td>10</td>\n",
       "      <td>0.04</td>\n",
       "      <td>{'n_estimators': 300, 'max_depth': 10, 'learni...</td>\n",
       "      <td>0.286256</td>\n",
       "      <td>0.435856</td>\n",
       "      <td>0.451821</td>\n",
       "      <td>0.428335</td>\n",
       "      <td>0.391095</td>\n",
       "      <td>0.397317</td>\n",
       "      <td>0.396803</td>\n",
       "      <td>0.378158</td>\n",
       "      <td>0.448488</td>\n",
       "      <td>0.313166</td>\n",
       "      <td>0.392730</td>\n",
       "      <td>0.052581</td>\n",
       "      <td>3</td>\n",
       "      <td>213.758318</td>\n",
       "      <td>189.700569</td>\n",
       "      <td>188.881656</td>\n",
       "      <td>197.917617</td>\n",
       "      <td>200.784997</td>\n",
       "      <td>211.059069</td>\n",
       "      <td>193.695039</td>\n",
       "      <td>212.565748</td>\n",
       "      <td>183.809603</td>\n",
       "      <td>207.457885</td>\n",
       "      <td>199.963050</td>\n",
       "      <td>10.303536</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.292262</td>\n",
       "      <td>1.918742</td>\n",
       "      <td>0.146840</td>\n",
       "      <td>0.031403</td>\n",
       "      <td>500</td>\n",
       "      <td>None</td>\n",
       "      <td>0.04</td>\n",
       "      <td>{'n_estimators': 500, 'max_depth': None, 'lear...</td>\n",
       "      <td>0.286363</td>\n",
       "      <td>0.434672</td>\n",
       "      <td>0.455326</td>\n",
       "      <td>0.425373</td>\n",
       "      <td>0.386692</td>\n",
       "      <td>0.400101</td>\n",
       "      <td>0.392710</td>\n",
       "      <td>0.368451</td>\n",
       "      <td>0.444957</td>\n",
       "      <td>0.301081</td>\n",
       "      <td>0.389572</td>\n",
       "      <td>0.054557</td>\n",
       "      <td>4</td>\n",
       "      <td>213.726447</td>\n",
       "      <td>190.098788</td>\n",
       "      <td>187.674077</td>\n",
       "      <td>198.943057</td>\n",
       "      <td>202.237161</td>\n",
       "      <td>210.084159</td>\n",
       "      <td>195.009504</td>\n",
       "      <td>215.884004</td>\n",
       "      <td>184.986472</td>\n",
       "      <td>211.108210</td>\n",
       "      <td>200.975188</td>\n",
       "      <td>10.782788</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.693975</td>\n",
       "      <td>1.135731</td>\n",
       "      <td>0.114168</td>\n",
       "      <td>0.019792</td>\n",
       "      <td>300</td>\n",
       "      <td>6</td>\n",
       "      <td>0.02</td>\n",
       "      <td>{'n_estimators': 300, 'max_depth': 6, 'learnin...</td>\n",
       "      <td>0.293121</td>\n",
       "      <td>0.440317</td>\n",
       "      <td>0.444315</td>\n",
       "      <td>0.426697</td>\n",
       "      <td>0.397617</td>\n",
       "      <td>0.396443</td>\n",
       "      <td>0.395657</td>\n",
       "      <td>0.385321</td>\n",
       "      <td>0.450091</td>\n",
       "      <td>0.307982</td>\n",
       "      <td>0.393756</td>\n",
       "      <td>0.051541</td>\n",
       "      <td>2</td>\n",
       "      <td>211.702532</td>\n",
       "      <td>188.200671</td>\n",
       "      <td>191.468042</td>\n",
       "      <td>198.484704</td>\n",
       "      <td>198.634441</td>\n",
       "      <td>211.365042</td>\n",
       "      <td>194.063205</td>\n",
       "      <td>210.117206</td>\n",
       "      <td>183.275437</td>\n",
       "      <td>209.023619</td>\n",
       "      <td>199.633490</td>\n",
       "      <td>9.897927</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.099955</td>\n",
       "      <td>0.419086</td>\n",
       "      <td>0.060223</td>\n",
       "      <td>0.014973</td>\n",
       "      <td>300</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'n_estimators': 300, 'max_depth': 3, 'learnin...</td>\n",
       "      <td>0.270349</td>\n",
       "      <td>0.395480</td>\n",
       "      <td>0.359776</td>\n",
       "      <td>0.359229</td>\n",
       "      <td>0.347338</td>\n",
       "      <td>0.339513</td>\n",
       "      <td>0.357821</td>\n",
       "      <td>0.358404</td>\n",
       "      <td>0.399627</td>\n",
       "      <td>0.264235</td>\n",
       "      <td>0.345177</td>\n",
       "      <td>0.042928</td>\n",
       "      <td>8</td>\n",
       "      <td>218.522497</td>\n",
       "      <td>203.277774</td>\n",
       "      <td>220.596681</td>\n",
       "      <td>221.842759</td>\n",
       "      <td>215.213904</td>\n",
       "      <td>231.301990</td>\n",
       "      <td>206.212856</td>\n",
       "      <td>219.318383</td>\n",
       "      <td>200.094395</td>\n",
       "      <td>222.237441</td>\n",
       "      <td>215.861868</td>\n",
       "      <td>9.256118</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.513936</td>\n",
       "      <td>0.636508</td>\n",
       "      <td>0.035922</td>\n",
       "      <td>0.012202</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': None, 'lear...</td>\n",
       "      <td>0.248147</td>\n",
       "      <td>0.344920</td>\n",
       "      <td>0.315869</td>\n",
       "      <td>0.324057</td>\n",
       "      <td>0.319669</td>\n",
       "      <td>0.296113</td>\n",
       "      <td>0.318822</td>\n",
       "      <td>0.316968</td>\n",
       "      <td>0.338258</td>\n",
       "      <td>0.251679</td>\n",
       "      <td>0.307450</td>\n",
       "      <td>0.031345</td>\n",
       "      <td>9</td>\n",
       "      <td>225.171770</td>\n",
       "      <td>220.279161</td>\n",
       "      <td>235.725650</td>\n",
       "      <td>234.019830</td>\n",
       "      <td>224.337622</td>\n",
       "      <td>246.500696</td>\n",
       "      <td>218.735875</td>\n",
       "      <td>233.482279</td>\n",
       "      <td>220.547608</td>\n",
       "      <td>226.029869</td>\n",
       "      <td>228.483036</td>\n",
       "      <td>8.319788</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12.159956</td>\n",
       "      <td>1.301260</td>\n",
       "      <td>0.151529</td>\n",
       "      <td>0.014062</td>\n",
       "      <td>500</td>\n",
       "      <td>8</td>\n",
       "      <td>0.02</td>\n",
       "      <td>{'n_estimators': 500, 'max_depth': 8, 'learnin...</td>\n",
       "      <td>0.293520</td>\n",
       "      <td>0.440482</td>\n",
       "      <td>0.452298</td>\n",
       "      <td>0.428416</td>\n",
       "      <td>0.398108</td>\n",
       "      <td>0.396949</td>\n",
       "      <td>0.400298</td>\n",
       "      <td>0.379122</td>\n",
       "      <td>0.453676</td>\n",
       "      <td>0.309588</td>\n",
       "      <td>0.395246</td>\n",
       "      <td>0.052723</td>\n",
       "      <td>1</td>\n",
       "      <td>211.582846</td>\n",
       "      <td>188.145295</td>\n",
       "      <td>188.717263</td>\n",
       "      <td>197.889493</td>\n",
       "      <td>198.472599</td>\n",
       "      <td>211.188144</td>\n",
       "      <td>192.572934</td>\n",
       "      <td>212.236228</td>\n",
       "      <td>182.080529</td>\n",
       "      <td>208.538554</td>\n",
       "      <td>199.142388</td>\n",
       "      <td>10.608978</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       9.857841      0.938545         0.103105        0.032921   \n",
       "1       7.262346      1.107602         0.076558        0.027454   \n",
       "2       5.244082      0.798453         0.062480        0.018483   \n",
       "3       1.466842      0.311525         0.028118        0.015307   \n",
       "4       8.243151      0.953824         0.085642        0.009882   \n",
       "5      12.292262      1.918742         0.146840        0.031403   \n",
       "6       7.693975      1.135731         0.114168        0.019792   \n",
       "7       2.099955      0.419086         0.060223        0.014973   \n",
       "8       3.513936      0.636508         0.035922        0.012202   \n",
       "9      12.159956      1.301260         0.151529        0.014062   \n",
       "\n",
       "  param_n_estimators param_max_depth param_learning_rate  \\\n",
       "0                300               9                0.01   \n",
       "1                200              10                0.01   \n",
       "2                200            None                 0.1   \n",
       "3                200               3                   2   \n",
       "4                300              10                0.04   \n",
       "5                500            None                0.04   \n",
       "6                300               6                0.02   \n",
       "7                300               3                0.01   \n",
       "8                100            None                0.01   \n",
       "9                500               8                0.02   \n",
       "\n",
       "                                              params  split0_test_R2  \\\n",
       "0  {'n_estimators': 300, 'max_depth': 9, 'learnin...        0.288668   \n",
       "1  {'n_estimators': 200, 'max_depth': 10, 'learni...        0.284622   \n",
       "2  {'n_estimators': 200, 'max_depth': None, 'lear...        0.272439   \n",
       "3  {'n_estimators': 200, 'max_depth': 3, 'learnin...       -0.056891   \n",
       "4  {'n_estimators': 300, 'max_depth': 10, 'learni...        0.286256   \n",
       "5  {'n_estimators': 500, 'max_depth': None, 'lear...        0.286363   \n",
       "6  {'n_estimators': 300, 'max_depth': 6, 'learnin...        0.293121   \n",
       "7  {'n_estimators': 300, 'max_depth': 3, 'learnin...        0.270349   \n",
       "8  {'n_estimators': 100, 'max_depth': None, 'lear...        0.248147   \n",
       "9  {'n_estimators': 500, 'max_depth': 8, 'learnin...        0.293520   \n",
       "\n",
       "   split1_test_R2  split2_test_R2  split3_test_R2  split4_test_R2  \\\n",
       "0        0.428440        0.418761        0.410989        0.387559   \n",
       "1        0.412311        0.391301        0.389452        0.374834   \n",
       "2        0.431204        0.453371        0.417627        0.370276   \n",
       "3       -0.037068       -0.031228       -0.027724       -0.027218   \n",
       "4        0.435856        0.451821        0.428335        0.391095   \n",
       "5        0.434672        0.455326        0.425373        0.386692   \n",
       "6        0.440317        0.444315        0.426697        0.397617   \n",
       "7        0.395480        0.359776        0.359229        0.347338   \n",
       "8        0.344920        0.315869        0.324057        0.319669   \n",
       "9        0.440482        0.452298        0.428416        0.398108   \n",
       "\n",
       "   split5_test_R2  split6_test_R2  split7_test_R2  split8_test_R2  \\\n",
       "0        0.383922        0.391160        0.384391        0.435925   \n",
       "1        0.362345        0.375417        0.371609        0.411402   \n",
       "2        0.382572        0.387557        0.368708        0.423840   \n",
       "3       -0.040343       -0.009783       -0.022472       -0.054521   \n",
       "4        0.397317        0.396803        0.378158        0.448488   \n",
       "5        0.400101        0.392710        0.368451        0.444957   \n",
       "6        0.396443        0.395657        0.385321        0.450091   \n",
       "7        0.339513        0.357821        0.358404        0.399627   \n",
       "8        0.296113        0.318822        0.316968        0.338258   \n",
       "9        0.396949        0.400298        0.379122        0.453676   \n",
       "\n",
       "   split9_test_R2  mean_test_R2  std_test_R2  rank_test_R2  split0_test_RMSE  \\\n",
       "0        0.290610      0.382042     0.049440             5        213.036175   \n",
       "1        0.284755      0.365805     0.043394             7        214.247793   \n",
       "2        0.287589      0.379518     0.056334             6        217.896575   \n",
       "3       -0.037243     -0.034449     0.013475            10        316.527214   \n",
       "4        0.313166      0.392730     0.052581             3        213.758318   \n",
       "5        0.301081      0.389572     0.054557             4        213.726447   \n",
       "6        0.307982      0.393756     0.051541             2        211.702532   \n",
       "7        0.264235      0.345177     0.042928             8        218.522497   \n",
       "8        0.251679      0.307450     0.031345             9        225.171770   \n",
       "9        0.309588      0.395246     0.052723             1        211.582846   \n",
       "\n",
       "   split1_test_RMSE  split2_test_RMSE  split3_test_RMSE  split4_test_RMSE  \\\n",
       "0        192.194579        200.272843        203.922917        201.951148   \n",
       "1        197.617869        209.734531        211.379402        206.147170   \n",
       "2        191.265128        188.347678        201.624713        207.650037   \n",
       "3        348.727433        355.322077        355.810792        338.722836   \n",
       "4        189.700569        188.881656        197.917617        200.784997   \n",
       "5        190.098788        187.674077        198.943057        202.237161   \n",
       "6        188.200671        191.468042        198.484704        198.634441   \n",
       "7        203.277774        220.596681        221.842759        215.213904   \n",
       "8        220.279161        235.725650        234.019830        224.337622   \n",
       "9        188.145295        188.717263        197.889493        198.472599   \n",
       "\n",
       "   split5_test_RMSE  split6_test_RMSE  split7_test_RMSE  split8_test_RMSE  \\\n",
       "0        215.750184        195.507263        210.435137        187.996662   \n",
       "1        223.306342        200.562374        214.804439        196.169768   \n",
       "2        216.222697        196.664084        215.795870        192.024370   \n",
       "3        364.327461        324.255831        349.513858        351.454233   \n",
       "4        211.059069        193.695039        212.565748        183.809603   \n",
       "5        210.084159        195.009504        215.884004        184.986472   \n",
       "6        211.365042        194.063205        210.117206        183.275437   \n",
       "7        231.301990        206.212856        219.318383        200.094395   \n",
       "8        246.500696        218.735875        233.482279        220.547608   \n",
       "9        211.188144        192.572934        212.236228        182.080529   \n",
       "\n",
       "   split9_test_RMSE  mean_test_RMSE  std_test_RMSE  rank_test_RMSE  \n",
       "0        214.270776      203.533768       9.220316               6  \n",
       "1        216.039366      209.000906       8.337601               4  \n",
       "2        215.183305      204.267446      11.087700               5  \n",
       "3        313.298658      341.796039      16.898637               1  \n",
       "4        207.457885      199.963050      10.303536               8  \n",
       "5        211.108210      200.975188      10.782788               7  \n",
       "6        209.023619      199.633490       9.897927               9  \n",
       "7        222.237441      215.861868       9.256118               3  \n",
       "8        226.029869      228.483036       8.319788               2  \n",
       "9        208.538554      199.142388      10.608978              10  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_data=lgb.Dataset(X_train,label=y_train)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = lgb.LGBMRegressor()\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.08, 0.04,0.02,0.01, 0.1, 1,2],\n",
    "    'n_estimators': [100,200,300,500],\n",
    "    'max_depth' : [None,3,4,5,6,7,8,9,10], \n",
    "}\n",
    "\n",
    "scoring = {'R2': make_scorer(r2_score), 'RMSE': make_scorer(mean_squared_error)}\n",
    "\n",
    "grid_search = RandomizedSearchCV(clf, param_distributions = param_grid, scoring=scoring, refit='R2',cv=10,n_iter=10, iid=False,n_jobs = -1)\n",
    "\n",
    "start = time.time()\n",
    "best_model = grid_search.fit(X, y)\n",
    "print(\"GridSearchCV took %.2f seconds to find optimal parameters.\" % (time.time() - start))\n",
    "print('Optimal Parameters found : ', best_model.best_estimator_.get_params())\n",
    "print('R2 for optimal model : ',best_model.best_score_)\n",
    "results = grid_search.cv_results_\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM RMSE : 13.85 (+/- 0.41)\n",
      "LGBM R2 Score: 0.43 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "#Normalization\n",
    "X = MinMaxScaler().fit_transform(data.drop(columns=['price']))\n",
    "y = data.price\n",
    "clf = lgb.LGBMRegressor(learning_rate=0.02,max_depth=8,n_estimators=500)\n",
    "_,r2_scores,_,_ = cross_val_scores('LGBM',clf,X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:36:42] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "GridSearchCV took 597.71 seconds to find optimal parameters.\n",
      "Optimal Parameters found :  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 1, 'gamma': 0, 'importance_type': 'gain', 'learning_rate': 0.02, 'max_delta_step': 0, 'max_depth': 8, 'min_child_weight': 1, 'missing': None, 'n_estimators': 300, 'n_jobs': 1, 'nthread': None, 'objective': 'reg:linear', 'random_state': 0, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': None, 'subsample': 1, 'verbosity': 1}\n",
      "R2 for optimal model :  0.3878550354527257\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_R2</th>\n",
       "      <th>split1_test_R2</th>\n",
       "      <th>split2_test_R2</th>\n",
       "      <th>split3_test_R2</th>\n",
       "      <th>split4_test_R2</th>\n",
       "      <th>split5_test_R2</th>\n",
       "      <th>split6_test_R2</th>\n",
       "      <th>split7_test_R2</th>\n",
       "      <th>split8_test_R2</th>\n",
       "      <th>split9_test_R2</th>\n",
       "      <th>mean_test_R2</th>\n",
       "      <th>std_test_R2</th>\n",
       "      <th>rank_test_R2</th>\n",
       "      <th>split0_test_RMSE</th>\n",
       "      <th>split1_test_RMSE</th>\n",
       "      <th>split2_test_RMSE</th>\n",
       "      <th>split3_test_RMSE</th>\n",
       "      <th>split4_test_RMSE</th>\n",
       "      <th>split5_test_RMSE</th>\n",
       "      <th>split6_test_RMSE</th>\n",
       "      <th>split7_test_RMSE</th>\n",
       "      <th>split8_test_RMSE</th>\n",
       "      <th>split9_test_RMSE</th>\n",
       "      <th>mean_test_RMSE</th>\n",
       "      <th>std_test_RMSE</th>\n",
       "      <th>rank_test_RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71.549472</td>\n",
       "      <td>6.846475</td>\n",
       "      <td>0.345230</td>\n",
       "      <td>0.068605</td>\n",
       "      <td>300</td>\n",
       "      <td>8</td>\n",
       "      <td>0.02</td>\n",
       "      <td>{'n_estimators': 300, 'max_depth': 8, 'learnin...</td>\n",
       "      <td>0.282364</td>\n",
       "      <td>0.425115</td>\n",
       "      <td>0.437864</td>\n",
       "      <td>0.427324</td>\n",
       "      <td>0.397081</td>\n",
       "      <td>0.401878</td>\n",
       "      <td>0.398649</td>\n",
       "      <td>0.370443</td>\n",
       "      <td>0.445180</td>\n",
       "      <td>0.292652</td>\n",
       "      <td>0.387855</td>\n",
       "      <td>0.054430</td>\n",
       "      <td>1</td>\n",
       "      <td>214.924060</td>\n",
       "      <td>193.312553</td>\n",
       "      <td>193.690775</td>\n",
       "      <td>198.267673</td>\n",
       "      <td>198.811158</td>\n",
       "      <td>209.461834</td>\n",
       "      <td>193.102500</td>\n",
       "      <td>215.202887</td>\n",
       "      <td>184.912117</td>\n",
       "      <td>213.653953</td>\n",
       "      <td>201.533951</td>\n",
       "      <td>10.346228</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26.782766</td>\n",
       "      <td>3.069226</td>\n",
       "      <td>0.268689</td>\n",
       "      <td>0.035485</td>\n",
       "      <td>200</td>\n",
       "      <td>4</td>\n",
       "      <td>0.02</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 4, 'learnin...</td>\n",
       "      <td>0.262407</td>\n",
       "      <td>0.419217</td>\n",
       "      <td>0.404979</td>\n",
       "      <td>0.396514</td>\n",
       "      <td>0.377024</td>\n",
       "      <td>0.386889</td>\n",
       "      <td>0.373624</td>\n",
       "      <td>0.375436</td>\n",
       "      <td>0.424185</td>\n",
       "      <td>0.271389</td>\n",
       "      <td>0.369166</td>\n",
       "      <td>0.053810</td>\n",
       "      <td>4</td>\n",
       "      <td>220.900882</td>\n",
       "      <td>195.295738</td>\n",
       "      <td>205.021642</td>\n",
       "      <td>208.934390</td>\n",
       "      <td>205.425108</td>\n",
       "      <td>214.711051</td>\n",
       "      <td>201.138132</td>\n",
       "      <td>213.496162</td>\n",
       "      <td>191.909628</td>\n",
       "      <td>220.076521</td>\n",
       "      <td>207.690925</td>\n",
       "      <td>9.329112</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.351784</td>\n",
       "      <td>0.630959</td>\n",
       "      <td>0.240567</td>\n",
       "      <td>0.028976</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.02</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 3, 'learnin...</td>\n",
       "      <td>-0.032265</td>\n",
       "      <td>0.258063</td>\n",
       "      <td>0.293642</td>\n",
       "      <td>0.250768</td>\n",
       "      <td>0.237682</td>\n",
       "      <td>0.324441</td>\n",
       "      <td>0.154553</td>\n",
       "      <td>0.218103</td>\n",
       "      <td>0.204620</td>\n",
       "      <td>-0.023943</td>\n",
       "      <td>0.188566</td>\n",
       "      <td>0.116973</td>\n",
       "      <td>6</td>\n",
       "      <td>309.151965</td>\n",
       "      <td>249.485823</td>\n",
       "      <td>243.384006</td>\n",
       "      <td>259.393491</td>\n",
       "      <td>251.372889</td>\n",
       "      <td>236.580416</td>\n",
       "      <td>271.485276</td>\n",
       "      <td>267.277710</td>\n",
       "      <td>265.087034</td>\n",
       "      <td>309.281550</td>\n",
       "      <td>266.250016</td>\n",
       "      <td>23.821472</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52.604829</td>\n",
       "      <td>2.326468</td>\n",
       "      <td>0.318679</td>\n",
       "      <td>0.045387</td>\n",
       "      <td>200</td>\n",
       "      <td>7</td>\n",
       "      <td>0.02</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 7, 'learnin...</td>\n",
       "      <td>0.272820</td>\n",
       "      <td>0.431416</td>\n",
       "      <td>0.435427</td>\n",
       "      <td>0.420177</td>\n",
       "      <td>0.398961</td>\n",
       "      <td>0.413452</td>\n",
       "      <td>0.378146</td>\n",
       "      <td>0.381463</td>\n",
       "      <td>0.441702</td>\n",
       "      <td>0.271981</td>\n",
       "      <td>0.384554</td>\n",
       "      <td>0.059640</td>\n",
       "      <td>2</td>\n",
       "      <td>217.782265</td>\n",
       "      <td>191.193887</td>\n",
       "      <td>194.530325</td>\n",
       "      <td>200.742119</td>\n",
       "      <td>198.191268</td>\n",
       "      <td>205.408548</td>\n",
       "      <td>199.686195</td>\n",
       "      <td>211.435976</td>\n",
       "      <td>186.071566</td>\n",
       "      <td>219.897729</td>\n",
       "      <td>202.493988</td>\n",
       "      <td>10.561012</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65.870458</td>\n",
       "      <td>4.685921</td>\n",
       "      <td>0.403035</td>\n",
       "      <td>0.039395</td>\n",
       "      <td>200</td>\n",
       "      <td>9</td>\n",
       "      <td>0.02</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 9, 'learnin...</td>\n",
       "      <td>0.252269</td>\n",
       "      <td>0.414941</td>\n",
       "      <td>0.438130</td>\n",
       "      <td>0.424108</td>\n",
       "      <td>0.396480</td>\n",
       "      <td>0.407795</td>\n",
       "      <td>0.383409</td>\n",
       "      <td>0.371893</td>\n",
       "      <td>0.432445</td>\n",
       "      <td>0.253001</td>\n",
       "      <td>0.377447</td>\n",
       "      <td>0.065419</td>\n",
       "      <td>3</td>\n",
       "      <td>223.937035</td>\n",
       "      <td>196.733601</td>\n",
       "      <td>193.598929</td>\n",
       "      <td>199.381008</td>\n",
       "      <td>199.009392</td>\n",
       "      <td>207.389781</td>\n",
       "      <td>197.996071</td>\n",
       "      <td>214.707129</td>\n",
       "      <td>189.156479</td>\n",
       "      <td>225.630787</td>\n",
       "      <td>204.754021</td>\n",
       "      <td>12.039208</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25.506512</td>\n",
       "      <td>2.119578</td>\n",
       "      <td>0.259313</td>\n",
       "      <td>0.034368</td>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 7, 'learnin...</td>\n",
       "      <td>-0.284551</td>\n",
       "      <td>-0.030083</td>\n",
       "      <td>-0.005805</td>\n",
       "      <td>-0.015765</td>\n",
       "      <td>0.022813</td>\n",
       "      <td>-0.065799</td>\n",
       "      <td>-0.098451</td>\n",
       "      <td>-0.096129</td>\n",
       "      <td>-0.077458</td>\n",
       "      <td>-0.315568</td>\n",
       "      <td>-0.096680</td>\n",
       "      <td>0.108652</td>\n",
       "      <td>7</td>\n",
       "      <td>384.708831</td>\n",
       "      <td>346.378683</td>\n",
       "      <td>346.562032</td>\n",
       "      <td>351.670420</td>\n",
       "      <td>322.225400</td>\n",
       "      <td>373.242137</td>\n",
       "      <td>352.728168</td>\n",
       "      <td>374.692264</td>\n",
       "      <td>359.098703</td>\n",
       "      <td>397.366657</td>\n",
       "      <td>360.867329</td>\n",
       "      <td>20.752352</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30.286632</td>\n",
       "      <td>2.349264</td>\n",
       "      <td>0.273368</td>\n",
       "      <td>0.030650</td>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>0.02</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 8, 'learnin...</td>\n",
       "      <td>-0.010825</td>\n",
       "      <td>0.276332</td>\n",
       "      <td>0.336709</td>\n",
       "      <td>0.294253</td>\n",
       "      <td>0.276354</td>\n",
       "      <td>0.371413</td>\n",
       "      <td>0.185955</td>\n",
       "      <td>0.242216</td>\n",
       "      <td>0.253059</td>\n",
       "      <td>0.003762</td>\n",
       "      <td>0.222923</td>\n",
       "      <td>0.122926</td>\n",
       "      <td>5</td>\n",
       "      <td>302.731002</td>\n",
       "      <td>243.342565</td>\n",
       "      <td>228.544811</td>\n",
       "      <td>244.338353</td>\n",
       "      <td>238.620626</td>\n",
       "      <td>220.130685</td>\n",
       "      <td>261.401434</td>\n",
       "      <td>259.035002</td>\n",
       "      <td>248.943099</td>\n",
       "      <td>300.913281</td>\n",
       "      <td>254.800086</td>\n",
       "      <td>26.293384</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>56.183480</td>\n",
       "      <td>2.432578</td>\n",
       "      <td>0.299925</td>\n",
       "      <td>0.056242</td>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_estimators': 500, 'max_depth': 3, 'learnin...</td>\n",
       "      <td>-2.631415</td>\n",
       "      <td>-1.736529</td>\n",
       "      <td>-7.769103</td>\n",
       "      <td>-5.668507</td>\n",
       "      <td>-2.320505</td>\n",
       "      <td>-1.526059</td>\n",
       "      <td>-2.574538</td>\n",
       "      <td>-2.492493</td>\n",
       "      <td>-2.785486</td>\n",
       "      <td>-118.402189</td>\n",
       "      <td>-14.790682</td>\n",
       "      <td>34.586384</td>\n",
       "      <td>10</td>\n",
       "      <td>1087.568680</td>\n",
       "      <td>920.193292</td>\n",
       "      <td>3021.499141</td>\n",
       "      <td>2308.720446</td>\n",
       "      <td>1094.929584</td>\n",
       "      <td>884.623962</td>\n",
       "      <td>1147.835298</td>\n",
       "      <td>1193.846895</td>\n",
       "      <td>1261.639176</td>\n",
       "      <td>36065.366454</td>\n",
       "      <td>4898.622293</td>\n",
       "      <td>10409.374728</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>33.484200</td>\n",
       "      <td>1.670057</td>\n",
       "      <td>0.284308</td>\n",
       "      <td>0.034791</td>\n",
       "      <td>100</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 9, 'learnin...</td>\n",
       "      <td>-7.562055</td>\n",
       "      <td>-7.433392</td>\n",
       "      <td>-5.622308</td>\n",
       "      <td>-7.202646</td>\n",
       "      <td>-5.974660</td>\n",
       "      <td>-5.218249</td>\n",
       "      <td>-7.277121</td>\n",
       "      <td>-6.992668</td>\n",
       "      <td>-6.843064</td>\n",
       "      <td>-9.308037</td>\n",
       "      <td>-6.943420</td>\n",
       "      <td>1.098421</td>\n",
       "      <td>9</td>\n",
       "      <td>2564.241055</td>\n",
       "      <td>2835.837310</td>\n",
       "      <td>2281.795282</td>\n",
       "      <td>2839.858389</td>\n",
       "      <td>2299.879330</td>\n",
       "      <td>2177.626043</td>\n",
       "      <td>2657.901705</td>\n",
       "      <td>2732.152303</td>\n",
       "      <td>2613.962203</td>\n",
       "      <td>3113.537070</td>\n",
       "      <td>2611.679069</td>\n",
       "      <td>277.042326</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>55.756437</td>\n",
       "      <td>11.543053</td>\n",
       "      <td>0.198388</td>\n",
       "      <td>0.120800</td>\n",
       "      <td>200</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 8, 'learnin...</td>\n",
       "      <td>-0.323288</td>\n",
       "      <td>-0.040869</td>\n",
       "      <td>0.024776</td>\n",
       "      <td>0.009329</td>\n",
       "      <td>-0.134436</td>\n",
       "      <td>-0.044501</td>\n",
       "      <td>-0.105309</td>\n",
       "      <td>-0.037473</td>\n",
       "      <td>-0.163610</td>\n",
       "      <td>-0.229262</td>\n",
       "      <td>-0.104464</td>\n",
       "      <td>0.104707</td>\n",
       "      <td>8</td>\n",
       "      <td>396.310187</td>\n",
       "      <td>350.005765</td>\n",
       "      <td>336.025204</td>\n",
       "      <td>342.982535</td>\n",
       "      <td>374.077707</td>\n",
       "      <td>365.783471</td>\n",
       "      <td>354.930668</td>\n",
       "      <td>354.641942</td>\n",
       "      <td>387.811846</td>\n",
       "      <td>371.297932</td>\n",
       "      <td>363.386726</td>\n",
       "      <td>18.317149</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      71.549472      6.846475         0.345230        0.068605   \n",
       "1      26.782766      3.069226         0.268689        0.035485   \n",
       "2      12.351784      0.630959         0.240567        0.028976   \n",
       "3      52.604829      2.326468         0.318679        0.045387   \n",
       "4      65.870458      4.685921         0.403035        0.039395   \n",
       "5      25.506512      2.119578         0.259313        0.034368   \n",
       "6      30.286632      2.349264         0.273368        0.030650   \n",
       "7      56.183480      2.432578         0.299925        0.056242   \n",
       "8      33.484200      1.670057         0.284308        0.034791   \n",
       "9      55.756437     11.543053         0.198388        0.120800   \n",
       "\n",
       "  param_n_estimators param_max_depth param_learning_rate  \\\n",
       "0                300               8                0.02   \n",
       "1                200               4                0.02   \n",
       "2                100               3                0.02   \n",
       "3                200               7                0.02   \n",
       "4                200               9                0.02   \n",
       "5                100               7                   1   \n",
       "6                100               8                0.02   \n",
       "7                500               3                   2   \n",
       "8                100               9                   2   \n",
       "9                200               8                   1   \n",
       "\n",
       "                                              params  split0_test_R2  \\\n",
       "0  {'n_estimators': 300, 'max_depth': 8, 'learnin...        0.282364   \n",
       "1  {'n_estimators': 200, 'max_depth': 4, 'learnin...        0.262407   \n",
       "2  {'n_estimators': 100, 'max_depth': 3, 'learnin...       -0.032265   \n",
       "3  {'n_estimators': 200, 'max_depth': 7, 'learnin...        0.272820   \n",
       "4  {'n_estimators': 200, 'max_depth': 9, 'learnin...        0.252269   \n",
       "5  {'n_estimators': 100, 'max_depth': 7, 'learnin...       -0.284551   \n",
       "6  {'n_estimators': 100, 'max_depth': 8, 'learnin...       -0.010825   \n",
       "7  {'n_estimators': 500, 'max_depth': 3, 'learnin...       -2.631415   \n",
       "8  {'n_estimators': 100, 'max_depth': 9, 'learnin...       -7.562055   \n",
       "9  {'n_estimators': 200, 'max_depth': 8, 'learnin...       -0.323288   \n",
       "\n",
       "   split1_test_R2  split2_test_R2  split3_test_R2  split4_test_R2  \\\n",
       "0        0.425115        0.437864        0.427324        0.397081   \n",
       "1        0.419217        0.404979        0.396514        0.377024   \n",
       "2        0.258063        0.293642        0.250768        0.237682   \n",
       "3        0.431416        0.435427        0.420177        0.398961   \n",
       "4        0.414941        0.438130        0.424108        0.396480   \n",
       "5       -0.030083       -0.005805       -0.015765        0.022813   \n",
       "6        0.276332        0.336709        0.294253        0.276354   \n",
       "7       -1.736529       -7.769103       -5.668507       -2.320505   \n",
       "8       -7.433392       -5.622308       -7.202646       -5.974660   \n",
       "9       -0.040869        0.024776        0.009329       -0.134436   \n",
       "\n",
       "   split5_test_R2  split6_test_R2  split7_test_R2  split8_test_R2  \\\n",
       "0        0.401878        0.398649        0.370443        0.445180   \n",
       "1        0.386889        0.373624        0.375436        0.424185   \n",
       "2        0.324441        0.154553        0.218103        0.204620   \n",
       "3        0.413452        0.378146        0.381463        0.441702   \n",
       "4        0.407795        0.383409        0.371893        0.432445   \n",
       "5       -0.065799       -0.098451       -0.096129       -0.077458   \n",
       "6        0.371413        0.185955        0.242216        0.253059   \n",
       "7       -1.526059       -2.574538       -2.492493       -2.785486   \n",
       "8       -5.218249       -7.277121       -6.992668       -6.843064   \n",
       "9       -0.044501       -0.105309       -0.037473       -0.163610   \n",
       "\n",
       "   split9_test_R2  mean_test_R2  std_test_R2  rank_test_R2  split0_test_RMSE  \\\n",
       "0        0.292652      0.387855     0.054430             1        214.924060   \n",
       "1        0.271389      0.369166     0.053810             4        220.900882   \n",
       "2       -0.023943      0.188566     0.116973             6        309.151965   \n",
       "3        0.271981      0.384554     0.059640             2        217.782265   \n",
       "4        0.253001      0.377447     0.065419             3        223.937035   \n",
       "5       -0.315568     -0.096680     0.108652             7        384.708831   \n",
       "6        0.003762      0.222923     0.122926             5        302.731002   \n",
       "7     -118.402189    -14.790682    34.586384            10       1087.568680   \n",
       "8       -9.308037     -6.943420     1.098421             9       2564.241055   \n",
       "9       -0.229262     -0.104464     0.104707             8        396.310187   \n",
       "\n",
       "   split1_test_RMSE  split2_test_RMSE  split3_test_RMSE  split4_test_RMSE  \\\n",
       "0        193.312553        193.690775        198.267673        198.811158   \n",
       "1        195.295738        205.021642        208.934390        205.425108   \n",
       "2        249.485823        243.384006        259.393491        251.372889   \n",
       "3        191.193887        194.530325        200.742119        198.191268   \n",
       "4        196.733601        193.598929        199.381008        199.009392   \n",
       "5        346.378683        346.562032        351.670420        322.225400   \n",
       "6        243.342565        228.544811        244.338353        238.620626   \n",
       "7        920.193292       3021.499141       2308.720446       1094.929584   \n",
       "8       2835.837310       2281.795282       2839.858389       2299.879330   \n",
       "9        350.005765        336.025204        342.982535        374.077707   \n",
       "\n",
       "   split5_test_RMSE  split6_test_RMSE  split7_test_RMSE  split8_test_RMSE  \\\n",
       "0        209.461834        193.102500        215.202887        184.912117   \n",
       "1        214.711051        201.138132        213.496162        191.909628   \n",
       "2        236.580416        271.485276        267.277710        265.087034   \n",
       "3        205.408548        199.686195        211.435976        186.071566   \n",
       "4        207.389781        197.996071        214.707129        189.156479   \n",
       "5        373.242137        352.728168        374.692264        359.098703   \n",
       "6        220.130685        261.401434        259.035002        248.943099   \n",
       "7        884.623962       1147.835298       1193.846895       1261.639176   \n",
       "8       2177.626043       2657.901705       2732.152303       2613.962203   \n",
       "9        365.783471        354.930668        354.641942        387.811846   \n",
       "\n",
       "   split9_test_RMSE  mean_test_RMSE  std_test_RMSE  rank_test_RMSE  \n",
       "0        213.653953      201.533951      10.346228              10  \n",
       "1        220.076521      207.690925       9.329112               7  \n",
       "2        309.281550      266.250016      23.821472               5  \n",
       "3        219.897729      202.493988      10.561012               9  \n",
       "4        225.630787      204.754021      12.039208               8  \n",
       "5        397.366657      360.867329      20.752352               4  \n",
       "6        300.913281      254.800086      26.293384               6  \n",
       "7      36065.366454     4898.622293   10409.374728               1  \n",
       "8       3113.537070     2611.679069     277.042326               2  \n",
       "9        371.297932      363.386726      18.317149               3  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_data=lgb.Dataset(X_train,label=y_train)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = XGBRegressor()\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.08, 0.04,0.02,0.01, 0.1, 1,2],\n",
    "    'n_estimators': [100,200,300,500],\n",
    "    'max_depth' : [None,3,4,5,6,7,8,9,10], \n",
    "}\n",
    "\n",
    "scoring = {'R2': make_scorer(r2_score), 'RMSE': make_scorer(mean_squared_error)}\n",
    "\n",
    "grid_search = RandomizedSearchCV(clf, param_distributions = param_grid, scoring=scoring, refit='R2',cv=10,n_iter=10, iid=False,n_jobs = -1)\n",
    "\n",
    "start = time.time()\n",
    "best_model = grid_search.fit(X, y)\n",
    "print(\"GridSearchCV took %.2f seconds to find optimal parameters.\" % (time.time() - start))\n",
    "print('Optimal Parameters found : ', best_model.best_estimator_.get_params())\n",
    "print('R2 for optimal model : ',best_model.best_score_)\n",
    "results = grid_search.cv_results_\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:37:12] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[07:37:35] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[07:37:58] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[07:38:23] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[07:38:46] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[07:39:09] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[07:39:33] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[07:39:55] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[09:01:07] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[09:01:32] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "XGBoost RMSE : 13.93 (+/- 0.47)\n",
      "XGBoost R2 Score: 0.42 (+/- 0.03)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([13.96058973697491,\n",
       "  12.924987655796802,\n",
       "  13.760179617232428,\n",
       "  14.081673129204956,\n",
       "  13.451123634354207,\n",
       "  14.645572261898629,\n",
       "  13.952757526460688,\n",
       "  14.426048899015614,\n",
       "  14.262813784888262,\n",
       "  13.826277021238303],\n",
       " [0.4086197803109033,\n",
       "  0.4827051930984386,\n",
       "  0.44190578170737005,\n",
       "  0.4026546884171932,\n",
       "  0.4435662394487645,\n",
       "  0.37545628212064897,\n",
       "  0.4255802055583673,\n",
       "  0.3943006406738691,\n",
       "  0.39572464224542603,\n",
       "  0.4170174520070761],\n",
       " 13.929202326706479,\n",
       " 0.4187530905588058)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBRegressor(learning_rate=0.02,max_depth=8,n_estimators=300)\n",
    "cross_val_scores('XGBoost', model, X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
